{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f61843a0-6d1b-4848-b84a-74a54184e1f3",
   "metadata": {},
   "source": [
    "## Prepare Dataset List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67faf7a5-8a0c-4ca4-8a77-89d501cf88ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset as dataset\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import scipy.ndimage as ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c4f1428-1b08-4f52-b16c-7e0010843d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 48\n",
    "lower = -350\n",
    "num_organ = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fc5e993-47f2-483b-be39-f7addf130f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(dataset):\n",
    "    def  __init__ (self , ct_dir, seg_dir):\n",
    "        self.ct_list = os.listdir(ct_dir)\n",
    "        self.seg_list = list(map(lambda x: x.replace('img', 'label'), self.ct_list))\n",
    "\n",
    "        self.ct_list = list(map(lambda x: os.path.normpath(os.path.join(ct_dir, x)), self.ct_list))\n",
    "        self.seg_list = list(map(lambda x: os.path.normpath(os.path.join(seg_dir, x)), self.seg_list))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        :param index:\n",
    "        :return: torch.Size([B, 1, 48, 256, 256]) torch.Size([B, 48, 256, 256])\n",
    "        \"\"\"\n",
    "        \n",
    "        ct_path = self.ct_list[index]\n",
    "        seg_path  = self.seg_list[index]\n",
    "\n",
    "        # Read CT and gold standard into memory\n",
    "        ct  =  sitk.ReadImage(ct_path , sitk.sitkInt16)\n",
    "        seg  =  sitk.ReadImage(seg_path , sitk.sitkUInt8)\n",
    "\n",
    "        ct_array = sitk.GetArrayFromImage(ct)\n",
    "        seg_array = sitk.GetArrayFromImage(seg)\n",
    "\n",
    "        #Randomly select 64 slices in the slice plane\n",
    "        start_slice = random.randint(0, ct_array.shape[0] - size)\n",
    "        end_slice = start_slice + size - 1\n",
    "\n",
    "        ct_array = ct_array[start_slice:end_slice + 1, :, :]\n",
    "        seg_array = seg_array [start_slice:end_slice + 1 , :, :]\n",
    "\n",
    "#         # Randomly rotate within 5 degrees with probability 0.5\n",
    "#         # If the angle is negative, it will rotate clockwise, if the angle is positive, it will rotate counterclockwise\n",
    "        if random.uniform(0, 1) >= 0.5:\n",
    "            angle = random.uniform(-5, 5)\n",
    "            ct_array = ndimage.rotate(ct_array, angle, axes =(1, 2), reshape = False , cval = lower);\n",
    "            seg_array = ndimage.rotate(seg_array, angle, axes = (1, 2), reshape = False, cval = 0);\n",
    "\n",
    "        #There is a probability of 0.5 without any modification, and the remaining 0.5 randomly selects a patch with a size of 0.8-0.5 and enlarges it to 256*256\n",
    "        if random.uniform(0, 1) >= 0.5:\n",
    "            ct_array, seg_array = self.zoom(ct_array, seg_array, patch_size=random.uniform(0.5, 0.8))\n",
    "\n",
    "        # After processing, convert array to tensor\n",
    "        ct_array = torch.FloatTensor(ct_array).unsqueeze(0)\n",
    "        seg_array = torch.FloatTensor(seg_array)\n",
    "        \n",
    "        # ct_array = F.interpolate(ct_array.unsqueeze(0), size=(256, 256), mode='bilinear', align_corners=False)\n",
    "        # seg_array = F.interpolate(seg_array.unsqueeze(0), size=(256, 256), mode='bilinear', align_corners=False).squeeze(0)\n",
    "        \n",
    "        # print(\"ct {} seg {}\".format(ct_array.shape, seg_array.shape))\n",
    "\n",
    "        return ct_array, seg_array\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ct_list)\n",
    "\n",
    "    def zoom(self, ct_array, seg_array, patch_size):\n",
    "        length = int(256*patch_size)\n",
    "\n",
    "        x1 = int(random.uniform(0, 255-length))\n",
    "        y1 = int(random.uniform(0, 255-length))\n",
    "\n",
    "        x2 = x1 + length\n",
    "        y2 = y1 + length\n",
    "\n",
    "        ct_array = ct_array[:, x1:x2 + 1, y1:y2 + 1]\n",
    "        seg_array = seg_array[:, x1:x2 + 1 , y1:y2 + 1]    \n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            ct_array = torch.FloatTensor(ct_array).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "            ct_array = Variable(ct_array)\n",
    "            ct_array = F.interpolate(ct_array, (size, 256, 256), mode='trilinear').squeeze().detach().numpy()\n",
    "\n",
    "            seg_array = torch.FloatTensor(seg_array).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "            seg_array = Variable(seg_array)\n",
    "            seg_array = F.interpolate(seg_array, (size, 256, 256), mode='trilinear').squeeze().detach().numpy()\n",
    "\n",
    "            return ct_array, seg_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2435a2d4-1cfa-4ba4-980b-dfa76299bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_dir = \"D:/skripsi/Dataset/train/CT\"\n",
    "seg_dir = \"D:/skripsi/Dataset/train/GT\"\n",
    "\n",
    "train_ds = Dataset(ct_dir, seg_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ac7b7d-31a2-43b9-8490-e90c3696d0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-0.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-1.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-10.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-11.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-12.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-13.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-14.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-15.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-16.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-17.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-18.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-19.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-2.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-20.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-21.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-22.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-23.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-24.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-25.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-26.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-27.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-28.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-29.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-3.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-4.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-5.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-6.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-7.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-8.nii',\n",
       " 'D:\\\\skripsi\\\\Dataset\\\\train\\\\GT\\\\label-9.nii']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.seg_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d22748-599a-4ed0-8770-21a8db7351bf",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "151051a1-e123-414b-bc35-721e68288634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DoubleConv(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(DoubleConv, self).__init__()\n",
    "#         self.conv = nn.Sequential(\n",
    "#             nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm3d(out_channels),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm3d(out_channels),\n",
    "#             nn.ReLU(inplace=True)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0976e6f5-8450-4047-b0bc-8d91c0b31490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Down(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(Down, self).__init__()\n",
    "#         self.mpconv = nn.Sequential(\n",
    "#             nn.MaxPool3d(2),\n",
    "#             DoubleConv(in_channels, out_channels)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.mpconv(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "530c2bd7-d42d-4ea7-a834-c06264b451ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Up(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "#         super(Up, self).__init__()\n",
    "#         if bilinear:\n",
    "#             self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "#         else:\n",
    "#             self.up = nn.ConvTranspose3d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "#         self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "#     def forward(self, x1, x2):\n",
    "#         x1 = self.up(x1)\n",
    "#         diffZ = x2.size()[4] - x1.size()[4]\n",
    "#         diffY = x2.size()[3] - x1.size()[3]\n",
    "#         diffX = x2.size()[2] - x1.size()[2]\n",
    "#         x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2,\n",
    "#                         diffY // 2, diffY - diffY // 2,\n",
    "#                         diffZ // 2, diffZ - diffZ // 2))\n",
    "#         x = torch.cat([x2, x1], dim=1)\n",
    "#         x = self.conv(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73942a62-838a-48a9-bd62-b276393973ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AttentionBlock(nn.Module):\n",
    "#     def __init__(self, in_channels):\n",
    "#         super(AttentionBlock, self).__init__()\n",
    "#         self.query_conv = nn.Conv3d(in_channels, in_channels // 8, kernel_size=1)\n",
    "#         self.key_conv = nn.Conv3d(in_channels, in_channels // 8, kernel_size=1)\n",
    "#         self.value_conv = nn.Conv3d(in_channels, in_channels, kernel_size=1)\n",
    "#         self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         batch_size, channels, height, width, depth = x.size()\n",
    "#         proj_query = self.query_conv(x).view(batch_size, -1, height * width * depth).permute(0, 2, 1)\n",
    "#         proj_key = self.key_conv(x).view(batch_size, -1, height * width * depth)\n",
    "#         energy = torch.bmm(proj_query, proj_key)\n",
    "#         attention = F.softmax(energy, dim=-1)\n",
    "#         proj_value = self.value_conv(x).view(batch_size, -1, height * width * depth)\n",
    "#         out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
    "#         out = out.view(batch_size, channels, height, width, depth)\n",
    "#         out = self.gamma * out + x\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2149984-25a8-4207-9fd3-28eca10f7df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AttentionUNet(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(AttentionUNet, self).__init__()\n",
    "#         self.inc = DoubleConv(in_channels, 64)\n",
    "#         self.down1 = Down(64, 128)\n",
    "#         self.down2 = Down(128, 256)\n",
    "#         self.down3 = Down(256, 512)\n",
    "#         self.attention = AttentionBlock(512)\n",
    "#         self.up3 = Up(512, 256)\n",
    "#         self.up2 = Up(256, 128)\n",
    "#         self.up1 = Up(128, 64)\n",
    "#         self.outc = nn.Conv3d(64, out_channels, kernel_size=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x1 = self.inc(x)\n",
    "#         x2 = self.down1(x1)\n",
    "#         x3 = self.down2(x2)\n",
    "#         x4 = self.down3(x3)\n",
    "#         x4 = self.attention(x4)\n",
    "#         x = self.up3(x4, x3)\n",
    "#         x = self.up2(x, x2)\n",
    "#         x = self.up1(x, x1)\n",
    "#         x = self.outc(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ae3b96c-df42-4d62-a2b9-08c585ddec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AttentionUNet(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # Downsample block 1\n",
    "#         self.conv1a = nn.Conv3d(in_channels, 16, kernel_size=3, padding=1)\n",
    "#         self.bn1a = nn.BatchNorm3d(16)\n",
    "#         self.conv1b = nn.Conv3d(16, 16, kernel_size=3, padding=1)\n",
    "#         self.bn1b = nn.BatchNorm3d(16)\n",
    "#         self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "#         # Downsample block 2\n",
    "#         self.conv2a = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n",
    "#         self.bn2a = nn.BatchNorm3d(32)\n",
    "#         self.conv2b = nn.Conv3d(32, 32, kernel_size=3, padding=1)\n",
    "#         self.bn2b = nn.BatchNorm3d(32)\n",
    "#         self.pool2 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "#         # Downsample block 3\n",
    "#         self.conv3a = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.bn3a = nn.BatchNorm3d(64)\n",
    "#         self.conv3b = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n",
    "#         self.bn3b = nn.BatchNorm3d(64)\n",
    "#         self.pool3 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "#         # Downsample block 4\n",
    "#         self.conv4a = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n",
    "#         self.bn4a = nn.BatchNorm3d(128)\n",
    "#         self.conv4b = nn.Conv3d(128, 128, kernel_size=3, padding=1)\n",
    "#         self.bn4b = nn.BatchNorm3d(128)\n",
    "#         self.pool4 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "#         # Downsample block 5\n",
    "#         self.conv5a = nn.Conv3d(128, 256, kernel_size=3, padding=1)\n",
    "#         self.bn5a = nn.BatchNorm3d(256)\n",
    "#         self.conv5b = nn.Conv3d(256, 256, kernel_size=3, padding=1)\n",
    "#         self.bn5b = nn.BatchNorm3d(256)\n",
    "\n",
    "#         # Upsample block 1\n",
    "#         self.upconv1 = nn.ConvTranspose3d(256, 128, kernel_size=2, stride=2)\n",
    "#         self.conv6a = nn.Conv3d(256, 128, kernel_size=3, padding=1)\n",
    "#         self.bn6a = nn.BatchNorm3d(128)\n",
    "#         self.conv6b = nn.Conv3d(128, 128, kernel_size=3, padding=1)\n",
    "#         self.bn6b = nn.BatchNorm3d(128)\n",
    "\n",
    "#         # Upsample block 2\n",
    "#         self.upconv2 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2)\n",
    "#         self.conv7a = nn.Conv3d(128, 64, kernel_size=3, padding=1)\n",
    "#         self.bn7a = nn.BatchNorm3d(64)\n",
    "#         self.conv7b = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n",
    "#         self.bn7b = nn.BatchNorm3d(64)\n",
    "        \n",
    "#         # Upsample block 3\n",
    "#         self.upconv3 = nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2)\n",
    "#         self.conv8a = nn.Conv3d(64, 32, kernel_size=3, padding=1)\n",
    "#         self.bn8a = nn.BatchNorm3d(32)\n",
    "#         self.conv8b = nn.Conv3d(32, 32, kernel_size=3, padding=1)\n",
    "#         self.bn8b = nn.BatchNorm3d(32)\n",
    "\n",
    "#         # Upsample block 4\n",
    "#         self.upconv4 = nn.ConvTranspose3d(32, 16, kernel_size=2, stride=2)\n",
    "#         self.conv9a = nn.Conv3d(32, 16, kernel_size=3, padding=1)\n",
    "#         self.bn9a = nn.BatchNorm3d(16)\n",
    "#         self.conv9b = nn.Conv3d(16, 16, kernel_size=3, padding=1)\n",
    "#         self.bn9b = nn.BatchNorm3d(16)\n",
    "\n",
    "#         # Attention gate\n",
    "#         self.attention_gate = nn.Sequential(\n",
    "#             nn.Conv3d(256, 64, kernel_size=1),\n",
    "#             nn.BatchNorm3d(64),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv3d(64, 1, kernel_size=1),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "        \n",
    "#         self.attention_gate_2 = nn.Sequential(\n",
    "#             nn.Conv3d(128, 64, kernel_size=1),\n",
    "#             nn.BatchNorm3d(64),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv3d(64, 1, kernel_size=1),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "        \n",
    "#         self.attention_gate_3 = nn.Sequential(\n",
    "#             nn.Conv3d(64, 64, kernel_size=1),\n",
    "#             nn.BatchNorm3d(64),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv3d(64, 1, kernel_size=1),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "        \n",
    "#         self.attention_gate_4 = nn.Sequential(\n",
    "#             nn.Conv3d(32, 64, kernel_size=1),\n",
    "#             nn.BatchNorm3d(64),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv3d(64, 1, kernel_size=1),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#         # Output convolution\n",
    "#         self.out_conv = nn.Conv3d(16, out_channels, kernel_size=1)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         # Downsample block 1\n",
    "#         x1 = F.relu(self.bn1a(self.conv1a(x)))\n",
    "#         x1 = F.relu(self.bn1b(self.conv1b(x1)))\n",
    "#         p1 = self.pool1(x1)\n",
    "\n",
    "#         # Downsample block 2\n",
    "#         x2 = F.relu(self.bn2a(self.conv2a(p1)))\n",
    "#         x2 = F.relu(self.bn2b(self.conv2b(x2)))\n",
    "#         p2 = self.pool2(x2)\n",
    "\n",
    "#         # Downsample block 3\n",
    "#         x3 = F.relu(self.bn3a(self.conv3a(p2)))\n",
    "#         x3 = F.relu(self.bn3b(self.conv3b(x3)))\n",
    "#         p3 = self.pool3(x3)\n",
    "\n",
    "#         # Downsample block 4\n",
    "#         x4 = F.relu(self.bn4a(self.conv4a(p3)))\n",
    "#         x4 = F.relu(self.bn4b(self.conv4b(x4)))\n",
    "#         p4 = self.pool4(x4)\n",
    "\n",
    "#         # Bottom block\n",
    "#         x5 = F.relu(self.bn5a(self.conv5a(p4)))\n",
    "#         x5 = F.relu(self.bn5b(self.conv5b(x5)))\n",
    "\n",
    "#         # Upsample block 1\n",
    "#         up1 = self.upconv1(x5)\n",
    "#         gate1 = self.attention_gate(torch.cat([up1, x4], dim=1))\n",
    "#         x6 = F.relu(self.bn6a(self.conv6a(torch.cat([up1, gate1*x4], dim=1))))\n",
    "#         x6 = F.relu(self.bn6b(self.conv6b(x6)))\n",
    "\n",
    "#         # Upsample block 2\n",
    "#         up2 = self.upconv2(x6)\n",
    "#         gate2 = self.attention_gate_2(torch.cat([up2, x3], dim=1))\n",
    "#         x7 = F.relu(self.bn7a(self.conv7a(torch.cat([up2, gate2*x3], dim=1))))\n",
    "#         x7 = F.relu(self.bn7b(self.conv7b(x7)))\n",
    "\n",
    "#         # Upsample block 3\n",
    "#         up3 = self.upconv3(x7)\n",
    "#         gate3 = self.attention_gate_3(torch.cat([up3, x2], dim=1))\n",
    "#         x8 = F.relu(self.bn8a(self.conv8a(torch.cat([up3, gate3*x2], dim=1))))\n",
    "#         x8 = F.relu(self.bn8b(self.conv8b(x8)))\n",
    "        \n",
    "#         # Upsample block 4\n",
    "#         up4 = self.upconv4(x8)\n",
    "#         gate4 = self.attention_gate_4(torch.cat([up4, x1], dim=1))\n",
    "#         x9 = F.relu(self.bn9a(self.conv9a(torch.cat([up4, gate4*x1], dim=1))))\n",
    "#         x9 = F.relu(self.bn9b(self.conv9b(x9)))\n",
    "\n",
    "#         # Output\n",
    "#         out = self.out_conv(x9)\n",
    "\n",
    "#         return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8ec279d-aea7-4d22-b363-041fad9112be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (stage1): ResUNet(\n",
       "    (encoder_stage1): Sequential(\n",
       "      (0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): PReLU(num_parameters=16)\n",
       "    )\n",
       "    (encoder_stage2): Sequential(\n",
       "      (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): PReLU(num_parameters=32)\n",
       "      (2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (3): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (encoder_stage3): Sequential(\n",
       "      (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): PReLU(num_parameters=64)\n",
       "      (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2))\n",
       "      (3): PReLU(num_parameters=64)\n",
       "      (4): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4))\n",
       "      (5): PReLU(num_parameters=64)\n",
       "    )\n",
       "    (encoder_stage4): Sequential(\n",
       "      (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(3, 3, 3), dilation=(3, 3, 3))\n",
       "      (1): PReLU(num_parameters=128)\n",
       "      (2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4))\n",
       "      (3): PReLU(num_parameters=128)\n",
       "      (4): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(5, 5, 5), dilation=(5, 5, 5))\n",
       "      (5): PReLU(num_parameters=128)\n",
       "    )\n",
       "    (decoder_stage1): Sequential(\n",
       "      (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): PReLU(num_parameters=256)\n",
       "      (2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (3): PReLU(num_parameters=256)\n",
       "      (4): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (5): PReLU(num_parameters=256)\n",
       "    )\n",
       "    (decoder_stage2): Sequential(\n",
       "      (0): Conv3d(192, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): PReLU(num_parameters=128)\n",
       "      (2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (3): PReLU(num_parameters=128)\n",
       "      (4): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (5): PReLU(num_parameters=128)\n",
       "    )\n",
       "    (decoder_stage3): Sequential(\n",
       "      (0): Conv3d(96, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): PReLU(num_parameters=64)\n",
       "      (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (3): PReLU(num_parameters=64)\n",
       "    )\n",
       "    (decoder_stage4): Sequential(\n",
       "      (0): Conv3d(48, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (down_conv1): Sequential(\n",
       "      (0): Conv3d(16, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "      (1): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (down_conv2): Sequential(\n",
       "      (0): Conv3d(32, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "      (1): PReLU(num_parameters=64)\n",
       "    )\n",
       "    (down_conv3): Sequential(\n",
       "      (0): Conv3d(64, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "      (1): PReLU(num_parameters=128)\n",
       "    )\n",
       "    (down_conv4): Sequential(\n",
       "      (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): PReLU(num_parameters=256)\n",
       "    )\n",
       "    (up_conv2): Sequential(\n",
       "      (0): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "      (1): PReLU(num_parameters=128)\n",
       "    )\n",
       "    (up_conv3): Sequential(\n",
       "      (0): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "      (1): PReLU(num_parameters=64)\n",
       "    )\n",
       "    (up_conv4): Sequential(\n",
       "      (0): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "      (1): PReLU(num_parameters=32)\n",
       "    )\n",
       "    (map): Sequential(\n",
       "      (0): Conv3d(32, 14, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (1): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_organ = 13\n",
    "dropout_rate = 0.3\n",
    "\n",
    "class ResUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    共9332094个可训练的参数, 九百三十万左右\n",
    "    \"\"\"\n",
    "    def __init__(self, training, inchannel, stage):\n",
    "        \"\"\"\n",
    "        :param training: 标志网络是属于训练阶段还是测试阶段\n",
    "        :param inchannel 网络最开始的输入通道数量\n",
    "        :param stage 标志网络属于第一阶段，还是第二阶段\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.training = training\n",
    "        self.stage = stage\n",
    "\n",
    "        self.encoder_stage1 = nn.Sequential(\n",
    "            nn.Conv3d(inchannel, 16, 3, 1, padding=1),\n",
    "            nn.PReLU(16),\n",
    "        )\n",
    "\n",
    "        self.encoder_stage2 = nn.Sequential(\n",
    "            nn.Conv3d(32, 32, 3, 1, padding=1),\n",
    "            nn.PReLU(32),\n",
    "\n",
    "            nn.Conv3d(32, 32, 3, 1, padding=1),\n",
    "            nn.PReLU(32),\n",
    "        )\n",
    "\n",
    "        self.encoder_stage3 = nn.Sequential(\n",
    "            nn.Conv3d(64, 64, 3, 1, padding=1),\n",
    "            nn.PReLU(64),\n",
    "\n",
    "            nn.Conv3d(64, 64, 3, 1, padding=2, dilation=2),\n",
    "            nn.PReLU(64),\n",
    "\n",
    "            nn.Conv3d(64, 64, 3, 1, padding=4, dilation=4),\n",
    "            nn.PReLU(64),\n",
    "        )\n",
    "\n",
    "        self.encoder_stage4 = nn.Sequential(\n",
    "            nn.Conv3d(128, 128, 3, 1, padding=3, dilation=3),\n",
    "            nn.PReLU(128),\n",
    "\n",
    "            nn.Conv3d(128, 128, 3, 1, padding=4, dilation=4),\n",
    "            nn.PReLU(128),\n",
    "\n",
    "            nn.Conv3d(128, 128, 3, 1, padding=5, dilation=5),\n",
    "            nn.PReLU(128),\n",
    "        )\n",
    "\n",
    "        self.decoder_stage1 = nn.Sequential(\n",
    "            nn.Conv3d(128, 256, 3, 1, padding=1),\n",
    "            nn.PReLU(256),\n",
    "\n",
    "            nn.Conv3d(256, 256, 3, 1, padding=1),\n",
    "            nn.PReLU(256),\n",
    "\n",
    "            nn.Conv3d(256, 256, 3, 1, padding=1),\n",
    "            nn.PReLU(256),\n",
    "        )\n",
    "\n",
    "        self.decoder_stage2 = nn.Sequential(\n",
    "            nn.Conv3d(128 + 64, 128, 3, 1, padding=1),\n",
    "            nn.PReLU(128),\n",
    "\n",
    "            nn.Conv3d(128, 128, 3, 1, padding=1),\n",
    "            nn.PReLU(128),\n",
    "\n",
    "            nn.Conv3d(128, 128, 3, 1, padding=1),\n",
    "            nn.PReLU(128),\n",
    "        )\n",
    "\n",
    "        self.decoder_stage3 = nn.Sequential(\n",
    "            nn.Conv3d(64 + 32, 64, 3, 1, padding=1),\n",
    "            nn.PReLU(64),\n",
    "\n",
    "            nn.Conv3d(64, 64, 3, 1, padding=1),\n",
    "            nn.PReLU(64),\n",
    "        )\n",
    "\n",
    "        self.decoder_stage4 = nn.Sequential(\n",
    "            nn.Conv3d(32 + 16, 32, 3, 1, padding=1),\n",
    "            nn.PReLU(32),\n",
    "        )\n",
    "\n",
    "        self.down_conv1 = nn.Sequential(\n",
    "            nn.Conv3d(16, 32, 2, 2),\n",
    "            nn.PReLU(32)\n",
    "        )\n",
    "\n",
    "        self.down_conv2 = nn.Sequential(\n",
    "            nn.Conv3d(32, 64, 2, 2),\n",
    "            nn.PReLU(64)\n",
    "        )\n",
    "\n",
    "        self.down_conv3 = nn.Sequential(\n",
    "            nn.Conv3d(64, 128, 2, 2),\n",
    "            nn.PReLU(128)\n",
    "        )\n",
    "\n",
    "        self.down_conv4 = nn.Sequential(\n",
    "            nn.Conv3d(128, 256, 3, 1, padding=1),\n",
    "            nn.PReLU(256)\n",
    "        )\n",
    "\n",
    "        self.up_conv2 = nn.Sequential(\n",
    "            nn.ConvTranspose3d(256, 128, 2, 2),\n",
    "            nn.PReLU(128)\n",
    "        )\n",
    "\n",
    "        self.up_conv3 = nn.Sequential(\n",
    "            nn.ConvTranspose3d(128, 64, 2, 2),\n",
    "            nn.PReLU(64)\n",
    "        )\n",
    "\n",
    "        self.up_conv4 = nn.Sequential(\n",
    "            nn.ConvTranspose3d(64, 32, 2, 2),\n",
    "            nn.PReLU(32)\n",
    "        )\n",
    "\n",
    "        self.map = nn.Sequential(\n",
    "            nn.Conv3d(32, num_organ + 1, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        long_range1 = self.encoder_stage1(inputs) + inputs\n",
    "\n",
    "        short_range1 = self.down_conv1(long_range1)\n",
    "\n",
    "        long_range2 = self.encoder_stage2(short_range1) + short_range1\n",
    "        long_range2 = F.dropout(long_range2, dropout_rate, self.training)\n",
    "\n",
    "        short_range2 = self.down_conv2(long_range2)\n",
    "\n",
    "        long_range3 = self.encoder_stage3(short_range2) + short_range2\n",
    "        long_range3 = F.dropout(long_range3, dropout_rate, self.training)\n",
    "\n",
    "        short_range3 = self.down_conv3(long_range3)\n",
    "\n",
    "        long_range4 = self.encoder_stage4(short_range3) + short_range3\n",
    "        long_range4 = F.dropout(long_range4, dropout_rate, self.training)\n",
    "\n",
    "        short_range4 = self.down_conv4(long_range4)\n",
    "\n",
    "        outputs = self.decoder_stage1(long_range4) + short_range4\n",
    "        outputs = F.dropout(outputs, dropout_rate, self.training)\n",
    "\n",
    "        short_range6 = self.up_conv2(outputs)\n",
    "\n",
    "        outputs = self.decoder_stage2(torch.cat([short_range6, long_range3], dim=1)) + short_range6\n",
    "        outputs = F.dropout(outputs, dropout_rate, self.training)\n",
    "\n",
    "        short_range7 = self.up_conv3(outputs)\n",
    "\n",
    "        outputs = self.decoder_stage3(torch.cat([short_range7, long_range2], dim=1)) + short_range7\n",
    "        outputs = F.dropout(outputs, dropout_rate, self.training)\n",
    "\n",
    "        short_range8 = self.up_conv4(outputs)\n",
    "\n",
    "        outputs = self.decoder_stage4(torch.cat([short_range8, long_range1], dim=1)) + short_range8\n",
    "\n",
    "        outputs = self.map(outputs)\n",
    "\n",
    "        # 返回概率图\n",
    "        return outputs\n",
    "\n",
    "\n",
    "# 定义最终的级连3D FCN\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, training):\n",
    "        super().__init__()\n",
    "\n",
    "        self.training = training\n",
    "\n",
    "        self.stage1 = ResUNet(training=training, inchannel=1, stage='stage1')\n",
    "        # self.stage2 = ResUNet(training=training, inchannel=num_organ + 2, stage='stage2')\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        首先将输入数据在轴向上缩小一倍，然后送入第一阶段网络中\n",
    "        得到一个粗糙尺度下的分割结果\n",
    "        然后将原始尺度大小的数据与第一步中得到的分割结果进行拼接，共同送入第二阶段网络中\n",
    "        得到最终的分割结果\n",
    "        共18656348个可训练的参数，一千八百万左右\n",
    "        \"\"\"\n",
    "        # 首先将输入缩小一倍\n",
    "        inputs_stage1 = F.upsample(inputs, (48, 128, 128), mode='trilinear')\n",
    "\n",
    "        # 得到第一阶段的结果\n",
    "        output_stage1 = self.stage1(inputs_stage1)\n",
    "        output_stage1 = F.upsample(output_stage1, (48, 256, 256), mode='trilinear')\n",
    "\n",
    "        # 将第一阶段的结果与原始输入数据进行拼接作为第二阶段的输入\n",
    "        # inputs_stage2 = torch.cat((output_stage1, inputs), dim=1)\n",
    "\n",
    "        # 得到第二阶段的结果\n",
    "        # output_stage2 = self.stage2(inputs_stage2)\n",
    "\n",
    "        # if self.training is True:\n",
    "        #     return output_stage1, output_stage2\n",
    "        # else:\n",
    "        #     return output_stage2\n",
    "        return output_stage1\n",
    "\n",
    "# 网络参数初始化函数\n",
    "def init(module):\n",
    "    if isinstance(module, nn.Conv3d) or isinstance(module, nn.ConvTranspose3d):\n",
    "        nn.init.kaiming_normal_(module.weight.data, 0.25)\n",
    "        nn.init.constant_(module.bias.data, 0)\n",
    "\n",
    "\n",
    "net = Net(training=True)\n",
    "net.apply(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "838d3bc6-f7af-4b6c-b0b6-d4a912dd3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = torch.compile(AttentionUNet)\n",
    "# net = AttentionUNet(1,13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f203a-db18-4259-8522-a46d354af30a",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "728163f0-0cfa-4a88-b4b7-be61e438906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dice_coef(ground_truth, predicted_segmentation):\n",
    "#     ground_truth_f = torch.flatten(ground_truth).cpu()\n",
    "#     predicted_segmentation_f = torch.flatten(predicted_segmentation).cpu()\n",
    "#     intersection = torch.sum(ground_truth_f * predicted_segmentation_f)\n",
    "#     return (2. * intersection) / (torch.sum(ground_truth_f) + torch.sum(predicted_segmentation_f))\n",
    "\n",
    "# def dice_coef_multilabel_loss(ground_truth, predicted_segmentation, numLabels=num_organ):\n",
    "#     dice = 1\n",
    "#     organ_target = torch.zeros((ground_truth.size(0), num_organ, 48, 256, 256))\n",
    "\n",
    "#     for organ_index in range(1, num_organ + 1):\n",
    "#         temp_target = torch.zeros(ground_truth.size())\n",
    "#         temp_target[ground_truth == organ_index] = 1\n",
    "#         organ_target[:, organ_index - 1, :, :, :] = temp_target\n",
    "        \n",
    "#     # organ_target.to(device)\n",
    "#     # organ_target = organ_target.cpu()\n",
    "#     # predicted_segmentation = predicted_segmentation.cpu()\n",
    "        \n",
    "#     for index in range(num_organ):\n",
    "#         dice -= dice_coef(organ_target[:,index,:,:,:], predicted_segmentation[:,index,:,:,:])\n",
    "#     return dice.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43dc794f-a853-42dd-b6ae-edba473b928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, target, pred_stage1):\n",
    "        \"\"\"\n",
    "        :param pred_stage1: 经过放大之后(B, 14, 48, 256, 256)\n",
    "        :param pred_stage2: (B, 14, 48, 256, 256)\n",
    "        :param target: (B, 48, 256, 256)\n",
    "        :return: Dice距离\n",
    "        \"\"\"\n",
    "\n",
    "        # 首先将金标准拆开\n",
    "        organ_target = torch.zeros((target.size(0), num_organ, 48, 256, 256))\n",
    "\n",
    "        for organ_index in range(1, num_organ + 1):\n",
    "            temp_target = torch.zeros(target.size())\n",
    "            temp_target[target == organ_index] = 1\n",
    "            organ_target[:, organ_index - 1, :, :, :] = temp_target\n",
    "            # organ_target: (B, 13, 48, 128, 128)\n",
    "\n",
    "        organ_target = organ_target.cuda()\n",
    "\n",
    "        # 计算第一阶段的loss\n",
    "        dice_stage1 = 0.0\n",
    "\n",
    "        for organ_index in range(1, num_organ + 1):\n",
    "            dice_stage1 += 2 * (pred_stage1[:, organ_index, :, :, :] * organ_target[:, organ_index - 1, :, :, :]).sum(dim=1).sum(dim=1).sum(\n",
    "                dim=1) / (pred_stage1[:, organ_index, :, :, :].pow(2).sum(dim=1).sum(dim=1).sum(dim=1) +\n",
    "                          organ_target[:, organ_index - 1, :, :, :].pow(2).sum(dim=1).sum(dim=1).sum(dim=1) + 1e-5)\n",
    "\n",
    "        dice_stage1 /= num_organ\n",
    "\n",
    "        # 返回的是dice距离\n",
    "        return (1 - dice_stage1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb8126e-38fc-4ee0-a84d-402fe602b7db",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdf1939f-0390-43ff-9828-ff87f41c5cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johan\\anaconda3\\envs\\FlaskAi\\lib\\site-packages\\torch\\nn\\functional.py:3742: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, step:0, loss:0.977, time:0.527 min\n",
      "epoch:1, step:4, loss:0.983, time:0.626 min\n",
      "epoch:1, step:8, loss:0.973, time:0.823 min\n",
      "epoch:1, step:12, loss:0.971, time:0.974 min\n",
      "epoch:1, step:16, loss:0.960, time:1.109 min\n",
      "epoch:1, step:20, loss:0.962, time:1.286 min\n",
      "epoch:1, step:24, loss:0.964, time:1.462 min\n",
      "epoch:1, step:28, loss:0.981, time:1.631 min\n",
      "epoch:2, step:0, loss:0.947, time:1.667 min\n",
      "epoch:2, step:4, loss:0.962, time:1.864 min\n",
      "epoch:2, step:8, loss:0.950, time:2.019 min\n",
      "epoch:2, step:12, loss:0.957, time:2.197 min\n",
      "epoch:2, step:16, loss:0.945, time:2.257 min\n",
      "epoch:2, step:20, loss:0.956, time:2.382 min\n",
      "epoch:2, step:24, loss:0.951, time:2.537 min\n",
      "epoch:2, step:28, loss:0.963, time:2.651 min\n",
      "epoch:3, step:0, loss:0.927, time:2.750 min\n",
      "epoch:3, step:4, loss:0.953, time:2.880 min\n",
      "epoch:3, step:8, loss:0.939, time:2.965 min\n",
      "epoch:3, step:12, loss:0.984, time:3.020 min\n",
      "epoch:3, step:16, loss:0.942, time:3.192 min\n",
      "epoch:3, step:20, loss:0.953, time:3.325 min\n",
      "epoch:3, step:24, loss:0.939, time:3.422 min\n",
      "epoch:3, step:28, loss:0.952, time:3.564 min\n",
      "epoch:4, step:0, loss:0.918, time:3.598 min\n",
      "epoch:4, step:4, loss:0.971, time:3.665 min\n",
      "epoch:4, step:8, loss:0.934, time:3.847 min\n",
      "epoch:4, step:12, loss:0.921, time:4.017 min\n",
      "epoch:4, step:16, loss:0.930, time:4.190 min\n",
      "epoch:4, step:20, loss:0.937, time:4.288 min\n",
      "epoch:4, step:24, loss:0.922, time:4.438 min\n",
      "epoch:4, step:28, loss:0.938, time:4.614 min\n",
      "epoch:5, step:0, loss:0.931, time:4.721 min\n",
      "epoch:5, step:4, loss:0.952, time:4.807 min\n",
      "epoch:5, step:8, loss:0.923, time:4.933 min\n",
      "epoch:5, step:12, loss:0.946, time:5.065 min\n",
      "epoch:5, step:16, loss:0.931, time:5.187 min\n",
      "epoch:5, step:20, loss:0.930, time:5.319 min\n",
      "epoch:5, step:24, loss:0.942, time:5.444 min\n",
      "epoch:5, step:28, loss:0.927, time:5.539 min\n",
      "epoch:6, step:0, loss:0.930, time:5.601 min\n",
      "epoch:6, step:4, loss:0.950, time:5.765 min\n",
      "epoch:6, step:8, loss:0.913, time:5.936 min\n",
      "epoch:6, step:12, loss:0.910, time:6.071 min\n",
      "epoch:6, step:16, loss:0.964, time:6.203 min\n",
      "epoch:6, step:20, loss:0.911, time:6.334 min\n",
      "epoch:6, step:24, loss:0.920, time:6.468 min\n",
      "epoch:6, step:28, loss:0.906, time:6.561 min\n",
      "epoch:7, step:0, loss:0.898, time:6.624 min\n",
      "epoch:7, step:4, loss:0.946, time:6.782 min\n",
      "epoch:7, step:8, loss:0.908, time:6.902 min\n",
      "epoch:7, step:12, loss:0.908, time:6.988 min\n",
      "epoch:7, step:16, loss:0.951, time:7.140 min\n",
      "epoch:7, step:20, loss:0.908, time:7.326 min\n",
      "epoch:7, step:24, loss:0.909, time:7.477 min\n",
      "epoch:7, step:28, loss:0.972, time:7.530 min\n",
      "epoch:8, step:0, loss:0.866, time:7.563 min\n",
      "epoch:8, step:4, loss:0.993, time:7.681 min\n",
      "epoch:8, step:8, loss:0.870, time:7.778 min\n",
      "epoch:8, step:12, loss:0.892, time:7.872 min\n",
      "epoch:8, step:16, loss:0.888, time:8.011 min\n",
      "epoch:8, step:20, loss:0.903, time:8.148 min\n",
      "epoch:8, step:24, loss:0.924, time:8.243 min\n",
      "epoch:8, step:28, loss:0.942, time:8.362 min\n",
      "epoch:9, step:0, loss:0.869, time:8.421 min\n",
      "epoch:9, step:4, loss:0.933, time:8.547 min\n",
      "epoch:9, step:8, loss:0.869, time:8.604 min\n",
      "epoch:9, step:12, loss:0.929, time:8.693 min\n",
      "epoch:9, step:16, loss:0.921, time:8.778 min\n",
      "epoch:9, step:20, loss:0.876, time:8.833 min\n",
      "epoch:9, step:24, loss:0.861, time:8.949 min\n",
      "epoch:9, step:28, loss:0.875, time:9.076 min\n",
      "epoch:10, step:0, loss:0.866, time:9.170 min\n",
      "epoch:10, step:4, loss:0.976, time:9.296 min\n",
      "epoch:10, step:8, loss:0.839, time:9.422 min\n",
      "epoch:10, step:12, loss:0.839, time:9.514 min\n",
      "epoch:10, step:16, loss:0.879, time:9.662 min\n",
      "epoch:10, step:20, loss:0.869, time:9.787 min\n",
      "epoch:10, step:24, loss:0.924, time:9.914 min\n",
      "epoch:10, step:28, loss:0.892, time:9.999 min\n",
      "epoch:11, step:0, loss:0.879, time:10.067 min\n",
      "epoch:11, step:4, loss:0.945, time:10.183 min\n",
      "epoch:11, step:8, loss:0.824, time:10.332 min\n",
      "epoch:11, step:12, loss:0.892, time:10.444 min\n",
      "epoch:11, step:16, loss:0.908, time:10.535 min\n",
      "epoch:11, step:20, loss:0.875, time:10.678 min\n",
      "epoch:11, step:24, loss:0.831, time:10.794 min\n",
      "epoch:11, step:28, loss:0.904, time:10.917 min\n",
      "epoch:12, step:0, loss:0.873, time:10.978 min\n",
      "epoch:12, step:4, loss:0.925, time:11.087 min\n",
      "epoch:12, step:8, loss:0.834, time:11.204 min\n",
      "epoch:12, step:12, loss:0.873, time:11.292 min\n",
      "epoch:12, step:16, loss:0.883, time:11.377 min\n",
      "epoch:12, step:20, loss:0.872, time:11.496 min\n",
      "epoch:12, step:24, loss:0.824, time:11.641 min\n",
      "epoch:12, step:28, loss:0.853, time:11.756 min\n",
      "epoch:13, step:0, loss:0.838, time:11.786 min\n",
      "epoch:13, step:4, loss:0.929, time:11.840 min\n",
      "epoch:13, step:8, loss:0.833, time:11.925 min\n",
      "epoch:13, step:12, loss:0.809, time:12.102 min\n",
      "epoch:13, step:16, loss:0.947, time:12.220 min\n",
      "epoch:13, step:20, loss:0.854, time:12.314 min\n",
      "epoch:13, step:24, loss:0.843, time:12.405 min\n",
      "epoch:13, step:28, loss:0.885, time:12.594 min\n",
      "epoch:14, step:0, loss:0.806, time:12.631 min\n",
      "epoch:14, step:4, loss:0.916, time:12.777 min\n",
      "epoch:14, step:8, loss:0.893, time:12.872 min\n",
      "epoch:14, step:12, loss:0.896, time:13.048 min\n",
      "epoch:14, step:16, loss:0.837, time:13.169 min\n",
      "epoch:14, step:20, loss:0.874, time:13.287 min\n",
      "epoch:14, step:24, loss:0.825, time:13.431 min\n",
      "epoch:14, step:28, loss:0.838, time:13.553 min\n",
      "epoch:15, step:0, loss:0.843, time:13.618 min\n",
      "epoch:15, step:4, loss:0.989, time:13.745 min\n",
      "epoch:15, step:8, loss:0.788, time:13.809 min\n",
      "epoch:15, step:12, loss:0.814, time:13.910 min\n",
      "epoch:15, step:16, loss:0.868, time:14.060 min\n",
      "epoch:15, step:20, loss:0.828, time:14.205 min\n",
      "epoch:15, step:24, loss:0.791, time:14.369 min\n",
      "epoch:15, step:28, loss:0.841, time:14.476 min\n",
      "epoch:16, step:0, loss:0.811, time:14.536 min\n",
      "epoch:16, step:4, loss:0.919, time:14.711 min\n",
      "epoch:16, step:8, loss:0.781, time:14.826 min\n",
      "epoch:16, step:12, loss:0.810, time:14.938 min\n",
      "epoch:16, step:16, loss:0.871, time:15.079 min\n",
      "epoch:16, step:20, loss:0.848, time:15.179 min\n",
      "epoch:16, step:24, loss:0.829, time:15.278 min\n",
      "epoch:16, step:28, loss:0.931, time:15.437 min\n",
      "epoch:17, step:0, loss:0.880, time:15.531 min\n",
      "epoch:17, step:4, loss:0.927, time:15.650 min\n",
      "epoch:17, step:8, loss:0.792, time:15.798 min\n",
      "epoch:17, step:12, loss:0.893, time:15.936 min\n",
      "epoch:17, step:16, loss:0.835, time:16.072 min\n",
      "epoch:17, step:20, loss:0.796, time:16.161 min\n",
      "epoch:17, step:24, loss:0.892, time:16.320 min\n",
      "epoch:17, step:28, loss:0.864, time:16.441 min\n",
      "epoch:18, step:0, loss:0.832, time:16.535 min\n",
      "epoch:18, step:4, loss:0.943, time:16.591 min\n",
      "epoch:18, step:8, loss:0.796, time:16.744 min\n",
      "epoch:18, step:12, loss:0.790, time:16.878 min\n",
      "epoch:18, step:16, loss:0.793, time:17.027 min\n",
      "epoch:18, step:20, loss:0.833, time:17.153 min\n",
      "epoch:18, step:24, loss:0.775, time:17.236 min\n",
      "epoch:18, step:28, loss:0.892, time:17.447 min\n",
      "epoch:19, step:0, loss:0.774, time:17.512 min\n",
      "epoch:19, step:4, loss:0.931, time:17.663 min\n",
      "epoch:19, step:8, loss:0.825, time:17.749 min\n",
      "epoch:19, step:12, loss:0.828, time:17.904 min\n",
      "epoch:19, step:16, loss:0.790, time:17.996 min\n",
      "epoch:19, step:20, loss:0.768, time:18.144 min\n",
      "epoch:19, step:24, loss:0.754, time:18.293 min\n",
      "epoch:19, step:28, loss:0.821, time:18.388 min\n",
      "epoch:20, step:0, loss:0.832, time:18.423 min\n",
      "epoch:20, step:4, loss:0.908, time:18.544 min\n",
      "epoch:20, step:8, loss:0.753, time:18.634 min\n",
      "epoch:20, step:12, loss:0.761, time:18.785 min\n",
      "epoch:20, step:16, loss:0.925, time:18.955 min\n",
      "epoch:20, step:20, loss:0.785, time:19.123 min\n",
      "epoch:20, step:24, loss:0.867, time:19.252 min\n",
      "epoch:20, step:28, loss:0.843, time:19.379 min\n",
      "epoch:21, step:0, loss:0.859, time:19.451 min\n",
      "epoch:21, step:4, loss:0.852, time:19.506 min\n",
      "epoch:21, step:8, loss:0.773, time:19.684 min\n",
      "epoch:21, step:12, loss:0.759, time:19.801 min\n",
      "epoch:21, step:16, loss:0.788, time:19.888 min\n",
      "epoch:21, step:20, loss:0.817, time:20.007 min\n",
      "epoch:21, step:24, loss:0.811, time:20.154 min\n",
      "epoch:21, step:28, loss:0.880, time:20.244 min\n",
      "epoch:22, step:0, loss:0.739, time:20.272 min\n",
      "epoch:22, step:4, loss:0.856, time:20.370 min\n",
      "epoch:22, step:8, loss:0.703, time:20.490 min\n",
      "epoch:22, step:12, loss:0.757, time:20.642 min\n",
      "epoch:22, step:16, loss:0.739, time:20.760 min\n",
      "epoch:22, step:20, loss:0.785, time:20.893 min\n",
      "epoch:22, step:24, loss:0.827, time:21.050 min\n",
      "epoch:22, step:28, loss:0.864, time:21.219 min\n",
      "epoch:23, step:0, loss:0.822, time:21.287 min\n",
      "epoch:23, step:4, loss:0.867, time:21.381 min\n",
      "epoch:23, step:8, loss:0.853, time:21.473 min\n",
      "epoch:23, step:12, loss:0.761, time:21.618 min\n",
      "epoch:23, step:16, loss:0.719, time:21.706 min\n",
      "epoch:23, step:20, loss:0.757, time:21.826 min\n",
      "epoch:23, step:24, loss:0.755, time:21.890 min\n",
      "epoch:23, step:28, loss:0.821, time:22.019 min\n",
      "epoch:24, step:0, loss:0.769, time:22.084 min\n",
      "epoch:24, step:4, loss:0.912, time:22.190 min\n",
      "epoch:24, step:8, loss:0.729, time:22.339 min\n",
      "epoch:24, step:12, loss:0.833, time:22.527 min\n",
      "epoch:24, step:16, loss:0.829, time:22.687 min\n",
      "epoch:24, step:20, loss:0.757, time:22.818 min\n",
      "epoch:24, step:24, loss:0.736, time:22.952 min\n",
      "epoch:24, step:28, loss:0.820, time:23.091 min\n",
      "epoch:25, step:0, loss:0.756, time:23.153 min\n",
      "epoch:25, step:4, loss:0.869, time:23.247 min\n",
      "epoch:25, step:8, loss:0.708, time:23.414 min\n",
      "epoch:25, step:12, loss:0.766, time:23.535 min\n",
      "epoch:25, step:16, loss:0.675, time:23.695 min\n",
      "epoch:25, step:20, loss:0.714, time:23.755 min\n",
      "epoch:25, step:24, loss:0.804, time:23.876 min\n",
      "epoch:25, step:28, loss:0.880, time:23.936 min\n",
      "epoch:26, step:0, loss:0.749, time:23.965 min\n",
      "epoch:26, step:4, loss:0.808, time:24.084 min\n",
      "epoch:26, step:8, loss:0.711, time:24.226 min\n",
      "epoch:26, step:12, loss:0.692, time:24.340 min\n",
      "epoch:26, step:16, loss:0.718, time:24.483 min\n",
      "epoch:26, step:20, loss:0.719, time:24.603 min\n",
      "epoch:26, step:24, loss:0.789, time:24.773 min\n",
      "epoch:26, step:28, loss:0.864, time:24.892 min\n",
      "epoch:27, step:0, loss:0.710, time:24.924 min\n",
      "epoch:27, step:4, loss:0.828, time:25.092 min\n",
      "epoch:27, step:8, loss:0.673, time:25.221 min\n",
      "epoch:27, step:12, loss:0.805, time:25.404 min\n",
      "epoch:27, step:16, loss:0.807, time:25.493 min\n",
      "epoch:27, step:20, loss:0.705, time:25.681 min\n",
      "epoch:27, step:24, loss:0.740, time:25.852 min\n",
      "epoch:27, step:28, loss:0.809, time:25.958 min\n",
      "epoch:28, step:0, loss:0.717, time:26.069 min\n",
      "epoch:28, step:4, loss:0.768, time:26.167 min\n",
      "epoch:28, step:8, loss:0.665, time:26.261 min\n",
      "epoch:28, step:12, loss:0.798, time:26.397 min\n",
      "epoch:28, step:16, loss:0.687, time:26.529 min\n",
      "epoch:28, step:20, loss:0.724, time:26.651 min\n",
      "epoch:28, step:24, loss:0.743, time:26.741 min\n",
      "epoch:28, step:28, loss:0.766, time:26.890 min\n",
      "epoch:29, step:0, loss:0.782, time:26.954 min\n",
      "epoch:29, step:4, loss:0.758, time:27.041 min\n",
      "epoch:29, step:8, loss:0.661, time:27.152 min\n",
      "epoch:29, step:12, loss:0.803, time:27.237 min\n",
      "epoch:29, step:16, loss:0.692, time:27.382 min\n",
      "epoch:29, step:20, loss:0.720, time:27.440 min\n",
      "epoch:29, step:24, loss:0.726, time:27.528 min\n",
      "epoch:29, step:28, loss:0.801, time:27.643 min\n",
      "epoch:30, step:0, loss:0.658, time:27.706 min\n",
      "epoch:30, step:4, loss:0.798, time:27.814 min\n",
      "epoch:30, step:8, loss:0.683, time:27.916 min\n",
      "epoch:30, step:12, loss:0.768, time:28.031 min\n",
      "epoch:30, step:16, loss:0.649, time:28.174 min\n",
      "epoch:30, step:20, loss:0.706, time:28.269 min\n",
      "epoch:30, step:24, loss:0.704, time:28.396 min\n",
      "epoch:30, step:28, loss:0.798, time:28.521 min\n",
      "epoch:31, step:0, loss:0.669, time:28.596 min\n",
      "epoch:31, step:4, loss:0.827, time:28.795 min\n",
      "epoch:31, step:8, loss:0.667, time:28.938 min\n",
      "epoch:31, step:12, loss:0.819, time:29.159 min\n",
      "epoch:31, step:16, loss:0.681, time:29.316 min\n",
      "epoch:31, step:20, loss:0.674, time:29.461 min\n",
      "epoch:31, step:24, loss:0.679, time:29.530 min\n",
      "epoch:31, step:28, loss:0.903, time:29.654 min\n",
      "epoch:32, step:0, loss:0.674, time:29.718 min\n",
      "epoch:32, step:4, loss:0.851, time:29.881 min\n",
      "epoch:32, step:8, loss:0.736, time:30.054 min\n",
      "epoch:32, step:12, loss:0.923, time:30.205 min\n",
      "epoch:32, step:16, loss:0.629, time:30.298 min\n",
      "epoch:32, step:20, loss:0.686, time:30.456 min\n",
      "epoch:32, step:24, loss:0.716, time:30.595 min\n",
      "epoch:32, step:28, loss:0.848, time:30.736 min\n",
      "epoch:33, step:0, loss:0.679, time:30.805 min\n",
      "epoch:33, step:4, loss:0.759, time:30.962 min\n",
      "epoch:33, step:8, loss:0.633, time:31.088 min\n",
      "epoch:33, step:12, loss:0.711, time:31.175 min\n",
      "epoch:33, step:16, loss:0.649, time:31.327 min\n",
      "epoch:33, step:20, loss:0.830, time:31.412 min\n",
      "epoch:33, step:24, loss:0.721, time:31.498 min\n",
      "epoch:33, step:28, loss:0.819, time:31.643 min\n",
      "epoch:34, step:0, loss:0.681, time:31.736 min\n",
      "epoch:34, step:4, loss:0.787, time:31.819 min\n",
      "epoch:34, step:8, loss:0.657, time:31.898 min\n",
      "epoch:34, step:12, loss:0.717, time:32.025 min\n",
      "epoch:34, step:16, loss:0.630, time:32.126 min\n",
      "epoch:34, step:20, loss:0.704, time:32.294 min\n",
      "epoch:34, step:24, loss:0.771, time:32.415 min\n",
      "epoch:34, step:28, loss:0.780, time:32.568 min\n",
      "epoch:35, step:0, loss:0.665, time:32.660 min\n",
      "epoch:35, step:4, loss:0.783, time:32.846 min\n",
      "epoch:35, step:8, loss:0.660, time:32.944 min\n",
      "epoch:35, step:12, loss:0.770, time:33.096 min\n",
      "epoch:35, step:16, loss:0.641, time:33.161 min\n",
      "epoch:35, step:20, loss:0.661, time:33.254 min\n",
      "epoch:35, step:24, loss:0.787, time:33.375 min\n",
      "epoch:35, step:28, loss:0.735, time:33.490 min\n",
      "epoch:36, step:0, loss:0.675, time:33.559 min\n",
      "epoch:36, step:4, loss:0.730, time:33.711 min\n",
      "epoch:36, step:8, loss:0.739, time:33.804 min\n",
      "epoch:36, step:12, loss:0.737, time:33.927 min\n",
      "epoch:36, step:16, loss:0.649, time:34.073 min\n",
      "epoch:36, step:20, loss:0.646, time:34.192 min\n",
      "epoch:36, step:24, loss:0.799, time:34.334 min\n",
      "epoch:36, step:28, loss:0.743, time:34.481 min\n",
      "epoch:37, step:0, loss:0.684, time:34.542 min\n",
      "epoch:37, step:4, loss:0.767, time:34.657 min\n",
      "epoch:37, step:8, loss:0.648, time:34.765 min\n",
      "epoch:37, step:12, loss:0.777, time:34.851 min\n",
      "epoch:37, step:16, loss:0.655, time:35.000 min\n",
      "epoch:37, step:20, loss:0.762, time:35.155 min\n",
      "epoch:37, step:24, loss:0.765, time:35.276 min\n",
      "epoch:37, step:28, loss:0.751, time:35.398 min\n",
      "epoch:38, step:0, loss:0.741, time:35.489 min\n",
      "epoch:38, step:4, loss:0.770, time:35.607 min\n",
      "epoch:38, step:8, loss:0.604, time:35.728 min\n",
      "epoch:38, step:12, loss:0.616, time:35.847 min\n",
      "epoch:38, step:16, loss:0.632, time:35.907 min\n",
      "epoch:38, step:20, loss:0.754, time:36.023 min\n",
      "epoch:38, step:24, loss:0.872, time:36.145 min\n",
      "epoch:38, step:28, loss:0.721, time:36.230 min\n",
      "epoch:39, step:0, loss:0.835, time:36.258 min\n",
      "epoch:39, step:4, loss:0.705, time:36.371 min\n",
      "epoch:39, step:8, loss:0.581, time:36.514 min\n",
      "epoch:39, step:12, loss:0.651, time:36.604 min\n",
      "epoch:39, step:16, loss:0.580, time:36.714 min\n",
      "epoch:39, step:20, loss:0.631, time:36.799 min\n",
      "epoch:39, step:24, loss:0.769, time:36.859 min\n",
      "epoch:39, step:28, loss:0.707, time:36.979 min\n",
      "epoch:40, step:0, loss:0.586, time:37.071 min\n",
      "epoch:40, step:4, loss:0.816, time:37.161 min\n",
      "epoch:40, step:8, loss:0.602, time:37.281 min\n",
      "epoch:40, step:12, loss:0.693, time:37.399 min\n",
      "epoch:40, step:16, loss:0.598, time:37.518 min\n",
      "epoch:40, step:20, loss:0.711, time:37.667 min\n",
      "epoch:40, step:24, loss:0.644, time:37.780 min\n",
      "epoch:40, step:28, loss:0.776, time:37.928 min\n",
      "epoch:41, step:0, loss:0.644, time:37.996 min\n",
      "epoch:41, step:4, loss:0.909, time:38.139 min\n",
      "epoch:41, step:8, loss:0.657, time:38.260 min\n",
      "epoch:41, step:12, loss:0.814, time:38.410 min\n",
      "epoch:41, step:16, loss:0.580, time:38.520 min\n",
      "epoch:41, step:20, loss:0.661, time:38.608 min\n",
      "epoch:41, step:24, loss:0.700, time:38.722 min\n",
      "epoch:41, step:28, loss:0.704, time:38.809 min\n",
      "epoch:42, step:0, loss:0.786, time:38.870 min\n",
      "epoch:42, step:4, loss:0.760, time:39.019 min\n",
      "epoch:42, step:8, loss:0.592, time:39.139 min\n",
      "epoch:42, step:12, loss:0.683, time:39.321 min\n",
      "epoch:42, step:16, loss:0.567, time:39.438 min\n",
      "epoch:42, step:20, loss:0.714, time:39.523 min\n",
      "epoch:42, step:24, loss:0.632, time:39.613 min\n",
      "epoch:42, step:28, loss:0.695, time:39.733 min\n",
      "epoch:43, step:0, loss:0.622, time:39.822 min\n",
      "epoch:43, step:4, loss:0.668, time:39.881 min\n",
      "epoch:43, step:8, loss:0.602, time:40.000 min\n",
      "epoch:43, step:12, loss:0.740, time:40.085 min\n",
      "epoch:43, step:16, loss:0.623, time:40.231 min\n",
      "epoch:43, step:20, loss:0.660, time:40.323 min\n",
      "epoch:43, step:24, loss:0.751, time:40.504 min\n",
      "epoch:43, step:28, loss:0.694, time:40.624 min\n",
      "epoch:44, step:0, loss:0.691, time:40.688 min\n",
      "epoch:44, step:4, loss:0.687, time:40.797 min\n",
      "epoch:44, step:8, loss:0.619, time:40.917 min\n",
      "epoch:44, step:12, loss:0.617, time:41.033 min\n",
      "epoch:44, step:16, loss:0.615, time:41.209 min\n",
      "epoch:44, step:20, loss:0.747, time:41.295 min\n",
      "epoch:44, step:24, loss:0.708, time:41.448 min\n",
      "epoch:44, step:28, loss:0.767, time:41.607 min\n",
      "epoch:45, step:0, loss:0.589, time:41.640 min\n",
      "epoch:45, step:4, loss:0.672, time:41.749 min\n",
      "epoch:45, step:8, loss:0.614, time:41.909 min\n",
      "epoch:45, step:12, loss:0.674, time:42.012 min\n",
      "epoch:45, step:16, loss:0.657, time:42.137 min\n",
      "epoch:45, step:20, loss:0.601, time:42.234 min\n",
      "epoch:45, step:24, loss:0.795, time:42.409 min\n",
      "epoch:45, step:28, loss:0.758, time:42.535 min\n",
      "epoch:46, step:0, loss:0.620, time:42.639 min\n",
      "epoch:46, step:4, loss:0.694, time:42.776 min\n",
      "epoch:46, step:8, loss:0.605, time:42.919 min\n",
      "epoch:46, step:12, loss:0.601, time:42.979 min\n",
      "epoch:46, step:16, loss:0.628, time:43.105 min\n",
      "epoch:46, step:20, loss:0.626, time:43.233 min\n",
      "epoch:46, step:24, loss:0.636, time:43.369 min\n",
      "epoch:46, step:28, loss:0.732, time:43.541 min\n",
      "epoch:47, step:0, loss:0.881, time:43.647 min\n",
      "epoch:47, step:4, loss:0.719, time:43.828 min\n",
      "epoch:47, step:8, loss:0.551, time:43.975 min\n",
      "epoch:47, step:12, loss:0.696, time:44.147 min\n",
      "epoch:47, step:16, loss:0.654, time:44.280 min\n",
      "epoch:47, step:20, loss:0.685, time:44.436 min\n",
      "epoch:47, step:24, loss:0.638, time:44.538 min\n",
      "epoch:47, step:28, loss:0.797, time:44.693 min\n",
      "epoch:48, step:0, loss:0.573, time:44.767 min\n",
      "epoch:48, step:4, loss:0.674, time:44.860 min\n",
      "epoch:48, step:8, loss:0.637, time:44.999 min\n",
      "epoch:48, step:12, loss:0.684, time:45.141 min\n",
      "epoch:48, step:16, loss:0.598, time:45.274 min\n",
      "epoch:48, step:20, loss:0.673, time:45.414 min\n",
      "epoch:48, step:24, loss:0.799, time:45.536 min\n",
      "epoch:48, step:28, loss:0.755, time:45.640 min\n",
      "epoch:49, step:0, loss:0.691, time:45.705 min\n",
      "epoch:49, step:4, loss:0.700, time:45.803 min\n",
      "epoch:49, step:8, loss:0.574, time:46.004 min\n",
      "epoch:49, step:12, loss:0.701, time:46.170 min\n",
      "epoch:49, step:16, loss:0.579, time:46.332 min\n",
      "epoch:49, step:20, loss:0.686, time:46.526 min\n",
      "epoch:49, step:24, loss:0.620, time:46.729 min\n",
      "epoch:49, step:28, loss:0.686, time:47.033 min\n",
      "epoch:50, step:0, loss:0.573, time:47.066 min\n",
      "epoch:50, step:4, loss:0.629, time:47.137 min\n",
      "epoch:50, step:8, loss:0.618, time:47.316 min\n",
      "epoch:50, step:12, loss:0.586, time:47.494 min\n",
      "epoch:50, step:16, loss:0.575, time:47.718 min\n",
      "epoch:50, step:20, loss:0.620, time:47.908 min\n",
      "epoch:50, step:24, loss:0.621, time:48.107 min\n",
      "epoch:50, step:28, loss:0.755, time:48.236 min\n",
      "epoch:51, step:0, loss:0.617, time:48.281 min\n",
      "epoch:51, step:4, loss:0.715, time:48.408 min\n",
      "epoch:51, step:8, loss:0.581, time:48.539 min\n",
      "epoch:51, step:12, loss:0.704, time:48.707 min\n",
      "epoch:51, step:16, loss:0.581, time:48.805 min\n",
      "epoch:51, step:20, loss:0.725, time:48.929 min\n",
      "epoch:51, step:24, loss:0.737, time:49.102 min\n",
      "epoch:51, step:28, loss:0.664, time:49.248 min\n",
      "epoch:52, step:0, loss:0.670, time:49.317 min\n",
      "epoch:52, step:4, loss:0.695, time:49.493 min\n",
      "epoch:52, step:8, loss:0.629, time:49.592 min\n",
      "epoch:52, step:12, loss:0.690, time:49.727 min\n",
      "epoch:52, step:16, loss:0.624, time:49.899 min\n",
      "epoch:52, step:20, loss:0.609, time:50.040 min\n",
      "epoch:52, step:24, loss:0.598, time:50.102 min\n",
      "epoch:52, step:28, loss:0.675, time:50.259 min\n",
      "epoch:53, step:0, loss:0.584, time:50.294 min\n",
      "epoch:53, step:4, loss:0.658, time:50.370 min\n",
      "epoch:53, step:8, loss:0.547, time:50.428 min\n",
      "epoch:53, step:12, loss:0.619, time:50.516 min\n",
      "epoch:53, step:16, loss:0.632, time:50.607 min\n",
      "epoch:53, step:20, loss:0.686, time:50.681 min\n",
      "epoch:53, step:24, loss:0.618, time:50.757 min\n",
      "epoch:53, step:28, loss:0.661, time:50.815 min\n",
      "epoch:54, step:0, loss:0.622, time:50.834 min\n",
      "epoch:54, step:4, loss:0.623, time:50.928 min\n",
      "epoch:54, step:8, loss:0.545, time:50.982 min\n",
      "epoch:54, step:12, loss:0.715, time:51.037 min\n",
      "epoch:54, step:16, loss:0.707, time:51.073 min\n",
      "epoch:54, step:20, loss:0.672, time:51.127 min\n",
      "epoch:54, step:24, loss:0.703, time:51.163 min\n",
      "epoch:54, step:28, loss:0.765, time:51.234 min\n",
      "epoch:55, step:0, loss:0.663, time:51.271 min\n",
      "epoch:55, step:4, loss:0.669, time:51.341 min\n",
      "epoch:55, step:8, loss:0.566, time:51.395 min\n",
      "epoch:55, step:12, loss:0.789, time:51.511 min\n",
      "epoch:55, step:16, loss:0.589, time:51.620 min\n",
      "epoch:55, step:20, loss:0.601, time:51.698 min\n",
      "epoch:55, step:24, loss:0.742, time:51.813 min\n",
      "epoch:55, step:28, loss:0.686, time:51.908 min\n",
      "epoch:56, step:0, loss:0.721, time:51.968 min\n",
      "epoch:56, step:4, loss:0.653, time:52.006 min\n",
      "epoch:56, step:8, loss:0.542, time:52.062 min\n",
      "epoch:56, step:12, loss:0.619, time:52.099 min\n",
      "epoch:56, step:16, loss:0.645, time:52.189 min\n",
      "epoch:56, step:20, loss:0.587, time:52.265 min\n",
      "epoch:56, step:24, loss:0.687, time:52.325 min\n",
      "epoch:56, step:28, loss:0.673, time:52.396 min\n",
      "epoch:57, step:0, loss:0.627, time:52.432 min\n",
      "epoch:57, step:4, loss:0.716, time:52.526 min\n",
      "epoch:57, step:8, loss:0.638, time:52.600 min\n",
      "epoch:57, step:12, loss:0.770, time:52.673 min\n",
      "epoch:57, step:16, loss:0.683, time:52.726 min\n",
      "epoch:57, step:20, loss:0.599, time:52.817 min\n",
      "epoch:57, step:24, loss:0.625, time:52.888 min\n",
      "epoch:57, step:28, loss:0.728, time:52.961 min\n",
      "epoch:58, step:0, loss:0.568, time:53.019 min\n",
      "epoch:58, step:4, loss:0.699, time:53.127 min\n",
      "epoch:58, step:8, loss:0.537, time:53.202 min\n",
      "epoch:58, step:12, loss:0.652, time:53.273 min\n",
      "epoch:58, step:16, loss:0.601, time:53.342 min\n",
      "epoch:58, step:20, loss:0.639, time:53.452 min\n",
      "epoch:58, step:24, loss:0.648, time:53.526 min\n",
      "epoch:58, step:28, loss:0.760, time:53.617 min\n",
      "epoch:59, step:0, loss:0.606, time:53.675 min\n",
      "epoch:59, step:4, loss:0.607, time:53.711 min\n",
      "epoch:59, step:8, loss:0.756, time:53.747 min\n",
      "epoch:59, step:12, loss:0.565, time:53.822 min\n",
      "epoch:59, step:16, loss:0.534, time:53.875 min\n",
      "epoch:59, step:20, loss:0.684, time:53.983 min\n",
      "epoch:59, step:24, loss:0.670, time:54.050 min\n",
      "epoch:59, step:28, loss:0.675, time:54.120 min\n",
      "epoch:60, step:0, loss:0.693, time:54.178 min\n",
      "epoch:60, step:4, loss:0.629, time:54.248 min\n",
      "epoch:60, step:8, loss:0.544, time:54.339 min\n",
      "epoch:60, step:12, loss:0.693, time:54.392 min\n",
      "epoch:60, step:16, loss:0.660, time:54.447 min\n",
      "epoch:60, step:20, loss:0.656, time:54.521 min\n",
      "epoch:60, step:24, loss:0.644, time:54.613 min\n",
      "epoch:60, step:28, loss:0.754, time:54.703 min\n",
      "epoch:61, step:0, loss:0.553, time:54.766 min\n",
      "epoch:61, step:4, loss:0.646, time:54.841 min\n",
      "epoch:61, step:8, loss:0.524, time:54.893 min\n",
      "epoch:61, step:12, loss:0.582, time:54.948 min\n",
      "epoch:61, step:16, loss:0.662, time:55.056 min\n",
      "epoch:61, step:20, loss:0.617, time:55.163 min\n",
      "epoch:61, step:24, loss:0.648, time:55.217 min\n",
      "epoch:61, step:28, loss:0.767, time:55.302 min\n",
      "epoch:62, step:0, loss:0.726, time:55.359 min\n",
      "epoch:62, step:4, loss:0.590, time:55.427 min\n",
      "epoch:62, step:8, loss:0.676, time:55.463 min\n",
      "epoch:62, step:12, loss:0.762, time:55.534 min\n",
      "epoch:62, step:16, loss:0.757, time:55.571 min\n",
      "epoch:62, step:20, loss:0.581, time:55.642 min\n",
      "epoch:62, step:24, loss:0.700, time:55.715 min\n",
      "epoch:62, step:28, loss:0.731, time:55.823 min\n",
      "epoch:63, step:0, loss:0.627, time:55.863 min\n",
      "epoch:63, step:4, loss:0.670, time:55.950 min\n",
      "epoch:63, step:8, loss:0.546, time:55.987 min\n",
      "epoch:63, step:12, loss:0.618, time:56.024 min\n",
      "epoch:63, step:16, loss:0.580, time:56.094 min\n",
      "epoch:63, step:20, loss:0.652, time:56.186 min\n",
      "epoch:63, step:24, loss:0.616, time:56.253 min\n",
      "epoch:63, step:28, loss:0.697, time:56.327 min\n",
      "epoch:64, step:0, loss:0.575, time:56.367 min\n",
      "epoch:64, step:4, loss:0.676, time:56.423 min\n",
      "epoch:64, step:8, loss:0.582, time:56.532 min\n",
      "epoch:64, step:12, loss:0.665, time:56.624 min\n",
      "epoch:64, step:16, loss:0.541, time:56.694 min\n",
      "epoch:64, step:20, loss:0.625, time:56.760 min\n",
      "epoch:64, step:24, loss:0.612, time:56.828 min\n",
      "epoch:64, step:28, loss:0.705, time:56.864 min\n",
      "epoch:65, step:0, loss:0.532, time:56.883 min\n",
      "epoch:65, step:4, loss:0.655, time:56.953 min\n",
      "epoch:65, step:8, loss:0.518, time:56.990 min\n",
      "epoch:65, step:12, loss:0.560, time:57.060 min\n",
      "epoch:65, step:16, loss:0.515, time:57.151 min\n",
      "epoch:65, step:20, loss:0.668, time:57.219 min\n",
      "epoch:65, step:24, loss:0.685, time:57.309 min\n",
      "epoch:65, step:28, loss:0.654, time:57.401 min\n",
      "epoch:66, step:0, loss:0.551, time:57.420 min\n",
      "epoch:66, step:4, loss:0.693, time:57.492 min\n",
      "epoch:66, step:8, loss:0.530, time:57.546 min\n",
      "epoch:66, step:12, loss:0.575, time:57.622 min\n",
      "epoch:66, step:16, loss:0.659, time:57.681 min\n",
      "epoch:66, step:20, loss:0.647, time:57.754 min\n",
      "epoch:66, step:24, loss:0.591, time:57.829 min\n",
      "epoch:66, step:28, loss:0.753, time:57.923 min\n",
      "epoch:67, step:0, loss:0.617, time:57.942 min\n",
      "epoch:67, step:4, loss:0.638, time:58.020 min\n",
      "epoch:67, step:8, loss:0.513, time:58.121 min\n",
      "epoch:67, step:12, loss:0.593, time:58.213 min\n",
      "epoch:67, step:16, loss:0.669, time:58.286 min\n",
      "epoch:67, step:20, loss:0.549, time:58.356 min\n",
      "epoch:67, step:24, loss:0.688, time:58.428 min\n",
      "epoch:67, step:28, loss:0.759, time:58.481 min\n",
      "epoch:68, step:0, loss:0.570, time:58.516 min\n",
      "epoch:68, step:4, loss:0.589, time:58.611 min\n",
      "epoch:68, step:8, loss:0.539, time:58.665 min\n",
      "epoch:68, step:12, loss:0.600, time:58.718 min\n",
      "epoch:68, step:16, loss:0.513, time:58.793 min\n",
      "epoch:68, step:20, loss:0.683, time:58.880 min\n",
      "epoch:68, step:24, loss:0.556, time:58.957 min\n",
      "epoch:68, step:28, loss:0.650, time:59.032 min\n",
      "epoch:69, step:0, loss:0.553, time:59.051 min\n",
      "epoch:69, step:4, loss:0.597, time:59.088 min\n",
      "epoch:69, step:8, loss:0.571, time:59.177 min\n",
      "epoch:69, step:12, loss:0.597, time:59.254 min\n",
      "epoch:69, step:16, loss:0.633, time:59.306 min\n",
      "epoch:69, step:20, loss:0.768, time:59.398 min\n",
      "epoch:69, step:24, loss:0.672, time:59.456 min\n",
      "epoch:69, step:28, loss:0.719, time:59.567 min\n",
      "epoch:70, step:0, loss:0.639, time:59.609 min\n",
      "epoch:70, step:4, loss:0.749, time:59.667 min\n",
      "epoch:70, step:8, loss:0.606, time:59.737 min\n",
      "epoch:70, step:12, loss:0.587, time:59.828 min\n",
      "epoch:70, step:16, loss:0.591, time:59.865 min\n",
      "epoch:70, step:20, loss:0.616, time:59.919 min\n",
      "epoch:70, step:24, loss:0.645, time:60.003 min\n",
      "epoch:70, step:28, loss:0.649, time:60.057 min\n",
      "epoch:71, step:0, loss:0.594, time:60.121 min\n",
      "epoch:71, step:4, loss:0.600, time:60.179 min\n",
      "epoch:71, step:8, loss:0.574, time:60.251 min\n",
      "epoch:71, step:12, loss:0.760, time:60.344 min\n",
      "epoch:71, step:16, loss:0.609, time:60.398 min\n",
      "epoch:71, step:20, loss:0.658, time:60.472 min\n",
      "epoch:71, step:24, loss:0.635, time:60.526 min\n",
      "epoch:71, step:28, loss:0.692, time:60.579 min\n",
      "epoch:72, step:0, loss:0.580, time:60.620 min\n",
      "epoch:72, step:4, loss:0.678, time:60.712 min\n",
      "epoch:72, step:8, loss:0.483, time:60.764 min\n",
      "epoch:72, step:12, loss:0.958, time:60.817 min\n",
      "epoch:72, step:16, loss:0.503, time:60.871 min\n",
      "epoch:72, step:20, loss:0.548, time:60.942 min\n",
      "epoch:72, step:24, loss:0.854, time:61.015 min\n",
      "epoch:72, step:28, loss:0.747, time:61.121 min\n",
      "epoch:73, step:0, loss:0.530, time:61.140 min\n",
      "epoch:73, step:4, loss:0.629, time:61.229 min\n",
      "epoch:73, step:8, loss:0.577, time:61.318 min\n",
      "epoch:73, step:12, loss:0.897, time:61.372 min\n",
      "epoch:73, step:16, loss:0.666, time:61.439 min\n",
      "epoch:73, step:20, loss:0.651, time:61.529 min\n",
      "epoch:73, step:24, loss:0.674, time:61.602 min\n",
      "epoch:73, step:28, loss:0.663, time:61.676 min\n",
      "epoch:74, step:0, loss:0.505, time:61.695 min\n",
      "epoch:74, step:4, loss:0.574, time:61.767 min\n",
      "epoch:74, step:8, loss:0.562, time:61.837 min\n",
      "epoch:74, step:12, loss:0.578, time:61.924 min\n",
      "epoch:74, step:16, loss:0.484, time:61.976 min\n",
      "epoch:74, step:20, loss:0.709, time:62.026 min\n",
      "epoch:74, step:24, loss:0.651, time:62.119 min\n",
      "epoch:74, step:28, loss:0.745, time:62.190 min\n",
      "epoch:75, step:0, loss:0.562, time:62.208 min\n",
      "epoch:75, step:4, loss:0.650, time:62.298 min\n",
      "epoch:75, step:8, loss:0.567, time:62.368 min\n",
      "epoch:75, step:12, loss:0.713, time:62.422 min\n",
      "epoch:75, step:16, loss:0.550, time:62.458 min\n",
      "epoch:75, step:20, loss:0.536, time:62.533 min\n",
      "epoch:75, step:24, loss:0.735, time:62.601 min\n",
      "epoch:75, step:28, loss:0.705, time:156.591 min\n",
      "epoch:76, step:0, loss:0.660, time:156.635 min\n",
      "epoch:76, step:4, loss:0.661, time:156.685 min\n",
      "epoch:76, step:8, loss:0.482, time:156.751 min\n",
      "epoch:76, step:12, loss:0.541, time:156.803 min\n",
      "epoch:76, step:16, loss:0.501, time:156.846 min\n",
      "epoch:76, step:20, loss:0.586, time:156.891 min\n",
      "epoch:76, step:24, loss:0.579, time:156.922 min\n",
      "epoch:76, step:28, loss:0.681, time:156.959 min\n",
      "epoch:77, step:0, loss:0.556, time:156.987 min\n",
      "epoch:77, step:4, loss:0.655, time:157.032 min\n",
      "epoch:77, step:8, loss:0.602, time:157.078 min\n",
      "epoch:77, step:12, loss:0.642, time:157.119 min\n",
      "epoch:77, step:16, loss:0.781, time:157.163 min\n",
      "epoch:77, step:20, loss:0.556, time:157.199 min\n",
      "epoch:77, step:24, loss:0.649, time:157.245 min\n",
      "epoch:77, step:28, loss:0.722, time:157.284 min\n",
      "epoch:78, step:0, loss:0.571, time:157.302 min\n",
      "epoch:78, step:4, loss:0.721, time:157.344 min\n",
      "epoch:78, step:8, loss:0.572, time:157.381 min\n",
      "epoch:78, step:12, loss:0.711, time:157.429 min\n",
      "epoch:78, step:16, loss:0.527, time:157.472 min\n",
      "epoch:78, step:20, loss:0.706, time:157.508 min\n",
      "epoch:78, step:24, loss:0.689, time:157.549 min\n",
      "epoch:78, step:28, loss:0.795, time:157.580 min\n",
      "epoch:79, step:0, loss:0.592, time:157.599 min\n",
      "epoch:79, step:4, loss:0.562, time:157.633 min\n",
      "epoch:79, step:8, loss:0.556, time:157.675 min\n",
      "epoch:79, step:12, loss:0.560, time:157.716 min\n",
      "epoch:79, step:16, loss:0.750, time:157.758 min\n",
      "epoch:79, step:20, loss:0.544, time:157.791 min\n",
      "epoch:79, step:24, loss:0.536, time:157.822 min\n",
      "epoch:79, step:28, loss:0.704, time:157.863 min\n",
      "epoch:80, step:0, loss:0.545, time:157.882 min\n",
      "epoch:80, step:4, loss:0.605, time:157.918 min\n",
      "epoch:80, step:8, loss:0.482, time:157.949 min\n",
      "epoch:80, step:12, loss:0.536, time:157.993 min\n",
      "epoch:80, step:16, loss:0.538, time:158.026 min\n",
      "epoch:80, step:20, loss:0.563, time:158.068 min\n",
      "epoch:80, step:24, loss:0.640, time:158.110 min\n",
      "epoch:80, step:28, loss:0.738, time:158.148 min\n",
      "epoch:81, step:0, loss:0.622, time:158.173 min\n",
      "epoch:81, step:4, loss:0.546, time:158.204 min\n",
      "epoch:81, step:8, loss:0.567, time:158.249 min\n",
      "epoch:81, step:12, loss:0.610, time:158.295 min\n",
      "epoch:81, step:16, loss:0.464, time:158.337 min\n",
      "epoch:81, step:20, loss:0.663, time:158.383 min\n",
      "epoch:81, step:24, loss:0.646, time:158.432 min\n",
      "epoch:81, step:28, loss:0.748, time:158.474 min\n",
      "epoch:82, step:0, loss:0.573, time:158.490 min\n",
      "epoch:82, step:4, loss:0.572, time:158.521 min\n",
      "epoch:82, step:8, loss:0.564, time:158.556 min\n",
      "epoch:82, step:12, loss:0.676, time:158.593 min\n",
      "epoch:82, step:16, loss:0.646, time:158.636 min\n",
      "epoch:82, step:20, loss:0.665, time:158.672 min\n",
      "epoch:82, step:24, loss:0.702, time:158.718 min\n",
      "epoch:82, step:28, loss:0.692, time:158.766 min\n",
      "epoch:83, step:0, loss:0.503, time:158.794 min\n",
      "epoch:83, step:4, loss:0.615, time:158.839 min\n",
      "epoch:83, step:8, loss:0.763, time:158.883 min\n",
      "epoch:83, step:12, loss:0.716, time:158.914 min\n",
      "epoch:83, step:16, loss:0.500, time:158.958 min\n",
      "epoch:83, step:20, loss:0.682, time:159.006 min\n",
      "epoch:83, step:24, loss:0.614, time:159.037 min\n",
      "epoch:83, step:28, loss:0.699, time:159.079 min\n",
      "epoch:84, step:0, loss:0.526, time:159.098 min\n",
      "epoch:84, step:4, loss:0.613, time:159.138 min\n",
      "epoch:84, step:8, loss:0.558, time:159.183 min\n",
      "epoch:84, step:12, loss:0.497, time:159.216 min\n",
      "epoch:84, step:16, loss:0.449, time:159.258 min\n",
      "epoch:84, step:20, loss:0.705, time:159.292 min\n",
      "epoch:84, step:24, loss:0.646, time:159.336 min\n",
      "epoch:84, step:28, loss:0.628, time:159.382 min\n",
      "epoch:85, step:0, loss:0.485, time:159.405 min\n",
      "epoch:85, step:4, loss:0.569, time:159.448 min\n",
      "epoch:85, step:8, loss:0.562, time:159.492 min\n",
      "epoch:85, step:12, loss:0.604, time:159.534 min\n",
      "epoch:85, step:16, loss:0.565, time:159.574 min\n",
      "epoch:85, step:20, loss:0.586, time:159.616 min\n",
      "epoch:85, step:24, loss:0.635, time:159.654 min\n",
      "epoch:85, step:28, loss:0.584, time:159.695 min\n",
      "epoch:86, step:0, loss:0.484, time:159.711 min\n",
      "epoch:86, step:4, loss:0.550, time:159.756 min\n",
      "epoch:86, step:8, loss:0.483, time:159.792 min\n",
      "epoch:86, step:12, loss:0.617, time:159.826 min\n",
      "epoch:86, step:16, loss:0.608, time:159.868 min\n",
      "epoch:86, step:20, loss:0.567, time:159.910 min\n",
      "epoch:86, step:24, loss:0.696, time:159.955 min\n",
      "epoch:86, step:28, loss:0.626, time:159.997 min\n",
      "epoch:87, step:0, loss:0.616, time:160.023 min\n",
      "epoch:87, step:4, loss:0.655, time:160.060 min\n",
      "epoch:87, step:8, loss:0.598, time:160.096 min\n",
      "epoch:87, step:12, loss:0.566, time:160.126 min\n",
      "epoch:87, step:16, loss:0.558, time:160.168 min\n",
      "epoch:87, step:20, loss:0.589, time:160.211 min\n",
      "epoch:87, step:24, loss:0.538, time:160.250 min\n",
      "epoch:87, step:28, loss:0.682, time:160.289 min\n",
      "epoch:88, step:0, loss:0.603, time:160.317 min\n",
      "epoch:88, step:4, loss:0.632, time:160.359 min\n",
      "epoch:88, step:8, loss:0.468, time:160.407 min\n",
      "epoch:88, step:12, loss:0.639, time:160.452 min\n",
      "epoch:88, step:16, loss:0.562, time:160.497 min\n",
      "epoch:88, step:20, loss:0.523, time:160.531 min\n",
      "epoch:88, step:24, loss:0.553, time:160.576 min\n",
      "epoch:88, step:28, loss:0.768, time:160.624 min\n",
      "epoch:89, step:0, loss:0.457, time:160.648 min\n",
      "epoch:89, step:4, loss:0.588, time:160.678 min\n",
      "epoch:89, step:8, loss:0.495, time:160.723 min\n",
      "epoch:89, step:12, loss:0.590, time:160.772 min\n",
      "epoch:89, step:16, loss:0.442, time:160.810 min\n",
      "epoch:89, step:20, loss:0.502, time:160.856 min\n",
      "epoch:89, step:24, loss:0.567, time:160.901 min\n",
      "epoch:89, step:28, loss:0.679, time:160.941 min\n",
      "epoch:90, step:0, loss:0.466, time:160.965 min\n",
      "epoch:90, step:4, loss:0.546, time:161.003 min\n",
      "epoch:90, step:8, loss:0.611, time:161.044 min\n",
      "epoch:90, step:12, loss:0.513, time:161.089 min\n",
      "epoch:90, step:16, loss:0.504, time:161.130 min\n",
      "epoch:90, step:20, loss:0.609, time:161.178 min\n",
      "epoch:90, step:24, loss:0.569, time:161.212 min\n",
      "epoch:90, step:28, loss:0.685, time:161.246 min\n",
      "epoch:91, step:0, loss:0.520, time:161.271 min\n",
      "epoch:91, step:4, loss:0.634, time:161.315 min\n",
      "epoch:91, step:8, loss:0.563, time:161.360 min\n",
      "epoch:91, step:12, loss:0.530, time:161.394 min\n",
      "epoch:91, step:16, loss:0.478, time:161.430 min\n",
      "epoch:91, step:20, loss:0.512, time:161.460 min\n",
      "epoch:91, step:24, loss:0.520, time:161.498 min\n",
      "epoch:91, step:28, loss:0.668, time:161.539 min\n",
      "epoch:92, step:0, loss:0.660, time:161.566 min\n",
      "epoch:92, step:4, loss:0.651, time:161.613 min\n",
      "epoch:92, step:8, loss:0.563, time:161.652 min\n",
      "epoch:92, step:12, loss:0.615, time:161.701 min\n",
      "epoch:92, step:16, loss:0.487, time:161.743 min\n",
      "epoch:92, step:20, loss:0.630, time:161.778 min\n",
      "epoch:92, step:24, loss:0.618, time:161.817 min\n",
      "epoch:92, step:28, loss:0.659, time:161.848 min\n",
      "epoch:93, step:0, loss:0.616, time:161.867 min\n",
      "epoch:93, step:4, loss:0.625, time:161.909 min\n",
      "epoch:93, step:8, loss:0.560, time:161.958 min\n",
      "epoch:93, step:12, loss:0.505, time:161.993 min\n",
      "epoch:93, step:16, loss:0.557, time:162.029 min\n",
      "epoch:93, step:20, loss:0.511, time:162.064 min\n",
      "epoch:93, step:24, loss:0.520, time:162.101 min\n",
      "epoch:93, step:28, loss:0.599, time:162.135 min\n",
      "epoch:94, step:0, loss:0.537, time:162.159 min\n",
      "epoch:94, step:4, loss:0.612, time:162.207 min\n",
      "epoch:94, step:8, loss:0.508, time:162.249 min\n",
      "epoch:94, step:12, loss:0.604, time:162.288 min\n",
      "epoch:94, step:16, loss:0.551, time:162.333 min\n",
      "epoch:94, step:20, loss:0.776, time:162.371 min\n",
      "epoch:94, step:24, loss:0.478, time:162.413 min\n",
      "epoch:94, step:28, loss:0.650, time:162.450 min\n",
      "epoch:95, step:0, loss:0.661, time:162.478 min\n",
      "epoch:95, step:4, loss:0.638, time:162.526 min\n",
      "epoch:95, step:8, loss:0.491, time:162.571 min\n",
      "epoch:95, step:12, loss:0.576, time:162.613 min\n",
      "epoch:95, step:16, loss:0.682, time:162.659 min\n",
      "epoch:95, step:20, loss:0.690, time:162.696 min\n",
      "epoch:95, step:24, loss:0.822, time:162.742 min\n",
      "epoch:95, step:28, loss:0.674, time:162.785 min\n",
      "epoch:96, step:0, loss:0.709, time:162.809 min\n",
      "epoch:96, step:4, loss:0.584, time:162.852 min\n",
      "epoch:96, step:8, loss:0.451, time:162.883 min\n",
      "epoch:96, step:12, loss:0.542, time:162.928 min\n",
      "epoch:96, step:16, loss:0.474, time:162.962 min\n",
      "epoch:96, step:20, loss:0.777, time:163.002 min\n",
      "epoch:96, step:24, loss:0.582, time:163.035 min\n",
      "epoch:96, step:28, loss:0.607, time:163.072 min\n",
      "epoch:97, step:0, loss:0.557, time:163.096 min\n",
      "epoch:97, step:4, loss:0.654, time:163.144 min\n",
      "epoch:97, step:8, loss:0.479, time:163.192 min\n",
      "epoch:97, step:12, loss:0.601, time:163.226 min\n",
      "epoch:97, step:16, loss:0.652, time:163.272 min\n",
      "epoch:97, step:20, loss:0.613, time:163.316 min\n",
      "epoch:97, step:24, loss:0.536, time:163.347 min\n",
      "epoch:97, step:28, loss:0.606, time:163.386 min\n",
      "epoch:98, step:0, loss:0.706, time:163.404 min\n",
      "epoch:98, step:4, loss:0.937, time:163.442 min\n",
      "epoch:98, step:8, loss:0.439, time:163.484 min\n",
      "epoch:98, step:12, loss:0.500, time:163.518 min\n",
      "epoch:98, step:16, loss:0.412, time:163.556 min\n",
      "epoch:98, step:20, loss:0.545, time:163.599 min\n",
      "epoch:98, step:24, loss:0.622, time:163.629 min\n",
      "epoch:98, step:28, loss:0.715, time:163.674 min\n",
      "epoch:99, step:0, loss:0.548, time:163.694 min\n",
      "epoch:99, step:4, loss:0.629, time:163.739 min\n",
      "epoch:99, step:8, loss:0.572, time:163.784 min\n",
      "epoch:99, step:12, loss:0.544, time:163.818 min\n",
      "epoch:99, step:16, loss:0.627, time:163.855 min\n",
      "epoch:99, step:20, loss:0.482, time:163.893 min\n",
      "epoch:99, step:24, loss:0.698, time:163.935 min\n",
      "epoch:99, step:28, loss:0.668, time:163.980 min\n",
      "epoch:100, step:0, loss:0.455, time:163.996 min\n",
      "epoch:100, step:4, loss:0.543, time:164.030 min\n",
      "epoch:100, step:8, loss:0.545, time:164.071 min\n",
      "epoch:100, step:12, loss:0.643, time:164.105 min\n",
      "epoch:100, step:16, loss:0.547, time:164.153 min\n",
      "epoch:100, step:20, loss:0.558, time:164.199 min\n",
      "epoch:100, step:24, loss:0.586, time:164.248 min\n",
      "epoch:100, step:28, loss:0.661, time:164.290 min\n",
      "epoch:101, step:0, loss:0.632, time:164.316 min\n",
      "epoch:101, step:4, loss:0.656, time:164.359 min\n",
      "epoch:101, step:8, loss:0.577, time:164.408 min\n",
      "epoch:101, step:12, loss:0.606, time:164.445 min\n",
      "epoch:101, step:16, loss:0.433, time:164.491 min\n",
      "epoch:101, step:20, loss:0.612, time:164.536 min\n",
      "epoch:101, step:24, loss:0.623, time:164.573 min\n",
      "epoch:101, step:28, loss:0.635, time:164.614 min\n",
      "epoch:102, step:0, loss:0.540, time:164.638 min\n",
      "epoch:102, step:4, loss:0.639, time:164.684 min\n",
      "epoch:102, step:8, loss:0.434, time:164.715 min\n",
      "epoch:102, step:12, loss:0.679, time:164.757 min\n",
      "epoch:102, step:16, loss:0.631, time:164.803 min\n",
      "epoch:102, step:20, loss:0.487, time:164.837 min\n",
      "epoch:102, step:24, loss:0.567, time:164.875 min\n",
      "epoch:102, step:28, loss:0.649, time:164.909 min\n",
      "epoch:103, step:0, loss:0.606, time:164.936 min\n",
      "epoch:103, step:4, loss:0.640, time:164.985 min\n",
      "epoch:103, step:8, loss:0.502, time:165.034 min\n",
      "epoch:103, step:12, loss:0.520, time:165.080 min\n",
      "epoch:103, step:16, loss:0.631, time:165.122 min\n",
      "epoch:103, step:20, loss:0.728, time:165.168 min\n",
      "epoch:103, step:24, loss:0.691, time:165.214 min\n",
      "epoch:103, step:28, loss:0.636, time:165.245 min\n",
      "epoch:104, step:0, loss:0.550, time:165.272 min\n",
      "epoch:104, step:4, loss:0.535, time:165.309 min\n",
      "epoch:104, step:8, loss:0.563, time:165.346 min\n",
      "epoch:104, step:12, loss:0.760, time:165.392 min\n",
      "epoch:104, step:16, loss:0.627, time:165.426 min\n",
      "epoch:104, step:20, loss:0.477, time:165.464 min\n",
      "epoch:104, step:24, loss:0.581, time:165.512 min\n",
      "epoch:104, step:28, loss:0.723, time:165.550 min\n",
      "epoch:105, step:0, loss:0.552, time:165.574 min\n",
      "epoch:105, step:4, loss:0.628, time:165.620 min\n",
      "epoch:105, step:8, loss:0.532, time:165.661 min\n",
      "epoch:105, step:12, loss:0.531, time:165.703 min\n",
      "epoch:105, step:16, loss:0.592, time:165.749 min\n",
      "epoch:105, step:20, loss:0.722, time:165.786 min\n",
      "epoch:105, step:24, loss:0.666, time:165.818 min\n",
      "epoch:105, step:28, loss:0.628, time:165.860 min\n",
      "epoch:106, step:0, loss:0.489, time:165.888 min\n",
      "epoch:106, step:4, loss:0.620, time:165.935 min\n",
      "epoch:106, step:8, loss:0.541, time:165.974 min\n",
      "epoch:106, step:12, loss:0.558, time:166.017 min\n",
      "epoch:106, step:16, loss:0.537, time:166.056 min\n",
      "epoch:106, step:20, loss:0.615, time:166.102 min\n",
      "epoch:106, step:24, loss:0.594, time:166.135 min\n",
      "epoch:106, step:28, loss:0.685, time:166.172 min\n",
      "epoch:107, step:0, loss:0.506, time:166.196 min\n",
      "epoch:107, step:4, loss:0.596, time:166.239 min\n",
      "epoch:107, step:8, loss:0.429, time:166.280 min\n",
      "epoch:107, step:12, loss:0.558, time:166.317 min\n",
      "epoch:107, step:16, loss:0.549, time:166.357 min\n",
      "epoch:107, step:20, loss:0.647, time:166.394 min\n",
      "epoch:107, step:24, loss:0.595, time:166.439 min\n",
      "epoch:107, step:28, loss:0.723, time:166.473 min\n",
      "epoch:108, step:0, loss:0.705, time:166.488 min\n",
      "epoch:108, step:4, loss:0.598, time:166.522 min\n",
      "epoch:108, step:8, loss:0.550, time:166.559 min\n",
      "epoch:108, step:12, loss:0.535, time:166.607 min\n",
      "epoch:108, step:16, loss:0.543, time:166.645 min\n",
      "epoch:108, step:20, loss:0.544, time:166.687 min\n",
      "epoch:108, step:24, loss:0.469, time:166.718 min\n",
      "epoch:108, step:28, loss:0.647, time:166.754 min\n",
      "epoch:109, step:0, loss:0.569, time:166.774 min\n",
      "epoch:109, step:4, loss:0.544, time:166.819 min\n",
      "epoch:109, step:8, loss:0.443, time:166.856 min\n",
      "epoch:109, step:12, loss:0.528, time:166.894 min\n",
      "epoch:109, step:16, loss:0.636, time:166.936 min\n",
      "epoch:109, step:20, loss:0.649, time:166.974 min\n",
      "epoch:109, step:24, loss:0.454, time:167.008 min\n",
      "epoch:109, step:28, loss:0.722, time:167.045 min\n",
      "epoch:110, step:0, loss:0.551, time:167.063 min\n",
      "epoch:110, step:4, loss:0.495, time:167.109 min\n",
      "epoch:110, step:8, loss:0.491, time:167.154 min\n",
      "epoch:110, step:12, loss:0.474, time:167.191 min\n",
      "epoch:110, step:16, loss:0.454, time:167.225 min\n",
      "epoch:110, step:20, loss:0.470, time:167.258 min\n",
      "epoch:110, step:24, loss:0.483, time:167.301 min\n",
      "epoch:110, step:28, loss:0.673, time:167.338 min\n",
      "epoch:111, step:0, loss:0.615, time:167.355 min\n",
      "epoch:111, step:4, loss:0.573, time:167.400 min\n",
      "epoch:111, step:8, loss:0.470, time:167.434 min\n",
      "epoch:111, step:12, loss:0.716, time:167.467 min\n",
      "epoch:111, step:16, loss:0.541, time:167.504 min\n",
      "epoch:111, step:20, loss:0.696, time:167.541 min\n",
      "epoch:111, step:24, loss:0.607, time:167.584 min\n",
      "epoch:111, step:28, loss:0.722, time:167.622 min\n",
      "epoch:112, step:0, loss:0.636, time:167.649 min\n",
      "epoch:112, step:4, loss:0.710, time:167.694 min\n",
      "epoch:112, step:8, loss:0.608, time:167.731 min\n",
      "epoch:112, step:12, loss:0.761, time:167.774 min\n",
      "epoch:112, step:16, loss:0.648, time:167.808 min\n",
      "epoch:112, step:20, loss:0.640, time:167.851 min\n",
      "epoch:112, step:24, loss:0.732, time:167.888 min\n",
      "epoch:113, step:4, loss:0.607, time:175.673 min\n",
      "epoch:113, step:8, loss:0.542, time:175.751 min\n",
      "epoch:113, step:12, loss:0.698, time:175.788 min\n",
      "epoch:113, step:16, loss:0.504, time:175.832 min\n",
      "epoch:113, step:20, loss:0.609, time:175.894 min\n",
      "epoch:113, step:24, loss:0.485, time:175.936 min\n",
      "epoch:113, step:28, loss:0.644, time:175.982 min\n",
      "epoch:114, step:0, loss:0.616, time:176.012 min\n",
      "epoch:114, step:4, loss:0.572, time:176.070 min\n",
      "epoch:114, step:8, loss:0.523, time:176.124 min\n",
      "epoch:114, step:12, loss:0.586, time:176.177 min\n",
      "epoch:114, step:16, loss:0.497, time:176.215 min\n",
      "epoch:114, step:20, loss:0.660, time:176.262 min\n",
      "epoch:114, step:24, loss:0.492, time:176.315 min\n",
      "epoch:114, step:28, loss:0.647, time:176.369 min\n",
      "epoch:115, step:0, loss:0.435, time:176.389 min\n",
      "epoch:115, step:4, loss:0.601, time:176.432 min\n",
      "epoch:115, step:8, loss:0.548, time:176.492 min\n",
      "epoch:115, step:12, loss:0.614, time:176.553 min\n",
      "epoch:115, step:16, loss:0.547, time:176.619 min\n",
      "epoch:115, step:20, loss:0.560, time:176.685 min\n",
      "epoch:115, step:24, loss:0.569, time:176.726 min\n",
      "epoch:115, step:28, loss:0.590, time:176.779 min\n",
      "epoch:116, step:0, loss:0.571, time:176.811 min\n",
      "epoch:116, step:4, loss:0.584, time:176.865 min\n",
      "epoch:116, step:8, loss:0.544, time:176.920 min\n",
      "epoch:116, step:12, loss:0.562, time:176.971 min\n",
      "epoch:116, step:16, loss:0.459, time:177.021 min\n",
      "epoch:116, step:20, loss:0.619, time:177.075 min\n",
      "epoch:116, step:24, loss:0.656, time:177.116 min\n",
      "epoch:116, step:28, loss:0.696, time:177.191 min\n",
      "epoch:117, step:0, loss:0.588, time:177.228 min\n",
      "epoch:117, step:4, loss:0.509, time:177.277 min\n",
      "epoch:117, step:8, loss:0.540, time:177.337 min\n",
      "epoch:117, step:12, loss:0.545, time:177.387 min\n",
      "epoch:117, step:16, loss:0.533, time:177.442 min\n",
      "epoch:117, step:20, loss:0.605, time:177.482 min\n",
      "epoch:117, step:24, loss:0.653, time:177.558 min\n",
      "epoch:117, step:28, loss:0.739, time:177.617 min\n",
      "epoch:118, step:0, loss:0.657, time:177.648 min\n",
      "epoch:118, step:4, loss:0.651, time:177.732 min\n",
      "epoch:118, step:8, loss:0.541, time:177.773 min\n",
      "epoch:118, step:12, loss:0.675, time:177.849 min\n",
      "epoch:118, step:16, loss:0.538, time:177.917 min\n",
      "epoch:118, step:20, loss:0.547, time:177.957 min\n",
      "epoch:118, step:24, loss:0.535, time:178.032 min\n",
      "epoch:118, step:28, loss:0.722, time:178.107 min\n",
      "epoch:119, step:0, loss:0.423, time:178.127 min\n",
      "epoch:119, step:4, loss:0.611, time:178.176 min\n",
      "epoch:119, step:8, loss:0.417, time:178.236 min\n",
      "epoch:119, step:12, loss:0.542, time:178.297 min\n",
      "epoch:119, step:16, loss:0.447, time:178.347 min\n",
      "epoch:119, step:20, loss:0.524, time:178.407 min\n",
      "epoch:119, step:24, loss:0.631, time:178.466 min\n",
      "epoch:119, step:28, loss:0.703, time:178.550 min\n",
      "epoch:120, step:0, loss:0.433, time:178.571 min\n",
      "epoch:120, step:4, loss:0.515, time:178.611 min\n",
      "epoch:120, step:8, loss:0.423, time:178.676 min\n",
      "epoch:120, step:12, loss:0.528, time:178.727 min\n",
      "epoch:120, step:16, loss:0.400, time:178.792 min\n",
      "epoch:120, step:20, loss:0.457, time:178.853 min\n",
      "epoch:120, step:24, loss:0.467, time:178.904 min\n",
      "epoch:120, step:28, loss:0.668, time:178.970 min\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "\n",
    "save_path = \"D:/skripsi/weights2/\"\n",
    "\n",
    "num_epochs = 120\n",
    "batch_size = 1\n",
    "learning_rate = 1e-4\n",
    "accumulation_steps = 8\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Define loss function and device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loss_func = DiceLoss()\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, pin_memory=True)\n",
    "\n",
    "opt = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "lr_decay = torch.optim.lr_scheduler.MultiStepLR(opt, [900])\n",
    "\n",
    "net = net.to(device)\n",
    "\n",
    "start = time()\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    mean_loss = 0\n",
    "    for step, (ct, seg) in enumerate(train_dl):\n",
    "        \n",
    "        ct = ct.cuda()\n",
    "\n",
    "        outputs_stage1 = net(ct)\n",
    "        loss = loss_func(seg, outputs_stage1)\n",
    "        \n",
    "        mean_loss += loss.item()\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        if step % 4 == 0:\n",
    "            print('epoch:{}, step:{}, loss:{:.3f}, time:{:.3f} min'\n",
    "                  .format(epoch, step, loss.item(), (time() - start) / 60))\n",
    "\n",
    "        \n",
    "    mean_loss = mean_loss / step\n",
    "    lr_decay.step()\n",
    "\n",
    "    # 每十个个epoch保存一次模型参数\n",
    "    # 网络模型的命名方式为：epoch轮数+当前minibatch的loss+本轮epoch的平均loss\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(net.state_dict(), save_path + '{}-{:.3f}-{:.3f}.pth'.format(epoch, loss.item(), mean_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea9f0f-b5de-4895-939f-d72ad89b7dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FlaskAi",
   "language": "python",
   "name": "flaskai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
